{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#**Installation**"
      ],
      "metadata": {
        "id": "Y5AJVnYo3JL0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install faiss-cpu\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S9mflUMR3Iom",
        "outputId": "d7580c93-4b0e-47bd-a2d8-a09d773273d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.7.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.6 MB 16.6 MB/s \n",
            "\u001b[?25hInstalling collected packages: faiss-cpu\n",
            "Successfully installed faiss-cpu-1.7.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Import liabraries**\n"
      ],
      "metadata": {
        "id": "o_HRJRpgvnN9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "\n",
        "import copy\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# from dataset_utils import *\n",
        "# from mnist_model import *\n",
        "# from adv_model import *\n",
        "# from dknn_attack_v2 import DKNNAttackV2\n",
        "# from dknn import DKNNL2\n",
        "# from utils import *\n",
        "\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import pickle\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "import faiss\n",
        "\n",
        "from torch.distributions.normal import Normal\n",
        "\n",
        "import logging\n",
        "import torch.optim as optim\n"
      ],
      "metadata": {
        "id": "AxlOWTDWvmwV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Faiss_utils**"
      ],
      "metadata": {
        "id": "TNp4I38F0Dom"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def swig_ptr_from_FloatTensor(x):\n",
        "    assert x.is_contiguous()\n",
        "    assert x.dtype == torch.float32\n",
        "    return faiss.cast_integer_to_float_ptr(x.storage().data_ptr())\n",
        "\n",
        "\n",
        "def swig_ptr_from_LongTensor(x):\n",
        "    assert x.is_contiguous()\n",
        "    assert x.dtype == torch.int64, 'dtype=%s' % x.dtype\n",
        "    return faiss.cast_integer_to_long_ptr(x.storage().data_ptr())\n",
        "\n",
        "\n",
        "def search_index_pytorch(index, x, k, D=None, I=None):\n",
        "    \"\"\"call the search function of an index with pytorch tensor I/O (CPU\n",
        "    and GPU supported)\"\"\"\n",
        "    assert x.is_contiguous()\n",
        "    n, d = x.size()\n",
        "    assert d == index.d\n",
        "\n",
        "    if D is None:\n",
        "        D = torch.empty((n, k), dtype=torch.float32, device=x.device)\n",
        "    else:\n",
        "        assert D.size() == (n, k)\n",
        "\n",
        "    if I is None:\n",
        "        I = torch.empty((n, k), dtype=torch.int64, device=x.device)\n",
        "    else:\n",
        "        assert I.size() == (n, k)\n",
        "    torch.cuda.synchronize()\n",
        "    xptr = swig_ptr_from_FloatTensor(x)\n",
        "    Iptr = swig_ptr_from_LongTensor(I)\n",
        "    Dptr = swig_ptr_from_FloatTensor(D)\n",
        "    index.search_c(n, xptr, k, Dptr, Iptr)\n",
        "    torch.cuda.synchronize()\n",
        "    return D, I"
      ],
      "metadata": {
        "id": "52clrJfs0CK2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Mnist_models**"
      ],
      "metadata": {
        "id": "eXxD90-m1l7y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Define MNIST models\n",
        "'''\n",
        "\n",
        "import copy\n",
        "import random\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.distributions.normal import Normal\n",
        "\n",
        "\n",
        "class KNNModel(nn.Module):\n",
        "    '''\n",
        "    A Pytorch model that apply an identiy function to the input (i.e. output =\n",
        "    input). It is used to simulate kNN on the input space so that it is\n",
        "    compatible with attacks implemented for DkNN.\n",
        "    '''\n",
        "\n",
        "    def __init__(self):\n",
        "        super(KNNModel, self).__init__()\n",
        "        self.identity = nn.Identity()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.identity(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "# ============================================================================ #\n",
        "\n",
        "\n",
        "class BasicModel(nn.Module):\n",
        "\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(BasicModel, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 64, kernel_size=8, stride=2, padding=3)\n",
        "        self.relu1 = nn.ReLU(inplace=True)\n",
        "        self.conv2 = nn.Conv2d(64, 128, kernel_size=6, stride=2, padding=3)\n",
        "        self.relu2 = nn.ReLU(inplace=True)\n",
        "        self.conv3 = nn.Conv2d(128, 128, kernel_size=5, stride=1, padding=0)\n",
        "        self.relu3 = nn.ReLU(inplace=True)\n",
        "        self.fc = nn.Linear(2048, num_classes)\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(\n",
        "                    m.weight, mode='fan_out', nonlinearity='relu')\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.relu1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.relu2(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.relu3(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "# ============================================================================ #\n",
        "\n",
        "\n",
        "class BasicModelV2(nn.Module):\n",
        "\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(BasicModelV2, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=5, stride=1, padding=2)\n",
        "        self.relu1 = nn.ReLU(inplace=True)\n",
        "        self.maxpool1 = nn.MaxPool2d(2, stride=2)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=5, stride=1, padding=2)\n",
        "        self.relu2 = nn.ReLU(inplace=True)\n",
        "        self.maxpool2 = nn.MaxPool2d(2, stride=2)\n",
        "        self.fc1 = nn.Linear(64 * 7 * 7, 1024)\n",
        "        self.relu3 = nn.ReLU(inplace=True)\n",
        "        self.fc2 = nn.Linear(1024, num_classes)\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(\n",
        "                    m.weight, mode='fan_out', nonlinearity='relu')\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu1(self.conv1(x))\n",
        "        x = self.maxpool1(x)\n",
        "        x = self.relu2(self.conv2(x))\n",
        "        x = self.maxpool2(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.relu3(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "# ============================================================================ #\n",
        "\n",
        "\n",
        "class ClassAuxVAE(nn.Module):\n",
        "\n",
        "    def __init__(self, input_dim, num_classes=10, latent_dim=20):\n",
        "        super(ClassAuxVAE, self).__init__()\n",
        "        self.input_dim = input_dim\n",
        "        self.latent_dim = latent_dim\n",
        "        self.input_dim_flat = 1\n",
        "        for dim in input_dim:\n",
        "            self.input_dim_flat *= dim\n",
        "        self.en_conv1 = nn.Conv2d(1, 64, kernel_size=8, stride=2, padding=3)\n",
        "        self.relu1 = nn.ReLU(inplace=True)\n",
        "        self.en_conv2 = nn.Conv2d(64, 128, kernel_size=6, stride=2, padding=3)\n",
        "        self.relu2 = nn.ReLU(inplace=True)\n",
        "        self.en_conv3 = nn.Conv2d(128, 128, kernel_size=5, stride=1, padding=0)\n",
        "        self.relu3 = nn.ReLU(inplace=True)\n",
        "        self.en_fc1 = nn.Linear(2048, 128)\n",
        "        self.relu4 = nn.ReLU(inplace=True)\n",
        "        self.en_mu = nn.Linear(128, latent_dim)\n",
        "        self.en_logvar = nn.Linear(128, latent_dim)\n",
        "\n",
        "        self.de_fc1 = nn.Linear(latent_dim, 128)\n",
        "        self.de_fc2 = nn.Linear(128, self.input_dim_flat * 2)\n",
        "\n",
        "        # TODO: experiment with different auxilary architecture\n",
        "        self.ax_fc1 = nn.Linear(latent_dim, 128)\n",
        "        self.ax_fc2 = nn.Linear(128, num_classes)\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(\n",
        "                    m.weight, mode='fan_out', nonlinearity='relu')\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "    def encode(self, x):\n",
        "        x = self.relu1(self.en_conv1(x))\n",
        "        x = self.relu2(self.en_conv2(x))\n",
        "        x = self.relu3(self.en_conv3(x))\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.relu4(self.en_fc1(x))\n",
        "        en_mu = self.en_mu(x)\n",
        "        # TODO: use tanh activation on logvar if unstable\n",
        "        # en_std = torch.exp(0.5 * x[:, self.latent_dim:])\n",
        "        en_logvar = self.en_logvar(x)\n",
        "        return en_mu, en_logvar\n",
        "\n",
        "    def reparameterize(self, mu, logvar):\n",
        "        std = torch.exp(0.5 * logvar)\n",
        "        eps = torch.randn_like(std)\n",
        "        return mu + eps * std\n",
        "\n",
        "    def decode(self, z):\n",
        "        x = F.relu(self.de_fc1(z))\n",
        "        x = self.de_fc2(x)\n",
        "        de_mu = x[:, :self.input_dim_flat]\n",
        "        # de_std = torch.exp(0.5 * x[:, self.input_dim_flat:])\n",
        "        de_logvar = x[:, self.input_dim_flat:].tanh()\n",
        "        out_dim = (z.size(0), ) + self.input_dim\n",
        "        return de_mu.view(out_dim).sigmoid(), de_logvar.view(out_dim)\n",
        "\n",
        "    def auxilary(self, z):\n",
        "        x = F.relu(self.ax_fc1(z))\n",
        "        x = self.ax_fc2(x)\n",
        "        return x\n",
        "\n",
        "    def forward(self, x):\n",
        "        en_mu, en_logvar = self.encode(x)\n",
        "        z = self.reparameterize(en_mu, en_logvar)\n",
        "        de_mu, de_logvar = self.decode(z)\n",
        "        y = self.auxilary(z)\n",
        "        return en_mu, en_logvar, de_mu, de_logvar, y\n",
        "\n",
        "\n",
        "# ============================================================================ #\n",
        "\n",
        "\n",
        "class VAE2(nn.Module):\n",
        "\n",
        "    def __init__(self, input_dim, num_classes=10, latent_dim=20):\n",
        "        super(VAE2, self).__init__()\n",
        "        self.input_dim = input_dim\n",
        "        self.latent_dim = latent_dim\n",
        "        self.input_dim_flat = 1\n",
        "        for dim in input_dim:\n",
        "            self.input_dim_flat *= dim\n",
        "        self.en_conv1 = nn.Conv2d(1, 64, kernel_size=8, stride=2, padding=3)\n",
        "        self.relu1 = nn.ReLU(inplace=True)\n",
        "        self.en_conv2 = nn.Conv2d(64, 128, kernel_size=6, stride=2, padding=3)\n",
        "        self.relu2 = nn.ReLU(inplace=True)\n",
        "        self.en_conv3 = nn.Conv2d(128, 128, kernel_size=5, stride=1, padding=0)\n",
        "        # self.relu3 = nn.ReLU(inplace=True)\n",
        "        self.relu3 = nn.ReLU()\n",
        "        self.en_fc1 = nn.Linear(2048, 400)\n",
        "        self.relu4 = nn.ReLU(inplace=True)\n",
        "        self.en_mu = nn.Linear(400, latent_dim)\n",
        "        self.en_logvar = nn.Linear(400, latent_dim)\n",
        "\n",
        "        self.de_fc1 = nn.Linear(latent_dim, 400)\n",
        "        self.de_relu1 = nn.ReLU(inplace=True)\n",
        "        self.de_fc2 = nn.Linear(400, self.input_dim_flat)\n",
        "\n",
        "    def encode(self, x):\n",
        "        x = self.relu1(self.en_conv1(x))\n",
        "        x = self.relu2(self.en_conv2(x))\n",
        "        x = self.relu3(self.en_conv3(x))\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.relu4(self.en_fc1(x))\n",
        "        en_mu = self.en_mu(x)\n",
        "        # TODO: use tanh activation on logvar if unstable\n",
        "        # en_std = torch.exp(0.5 * x[:, self.latent_dim:])\n",
        "        en_logvar = self.en_logvar(x)\n",
        "        return en_mu, en_logvar\n",
        "\n",
        "    def reparameterize(self, mu, logvar):\n",
        "        std = torch.exp(0.5 * logvar)\n",
        "        eps = torch.randn_like(std)\n",
        "        return mu + eps * std\n",
        "\n",
        "    def decode(self, z):\n",
        "        x = self.de_relu1(self.de_fc1(z))\n",
        "        x = self.de_fc2(x)\n",
        "        out_dim = (z.size(0), ) + self.input_dim\n",
        "        return x.view(out_dim).sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        en_mu, en_logvar = self.encode(x)\n",
        "        z = self.reparameterize(en_mu, en_logvar)\n",
        "        output = self.decode(z)\n",
        "        return en_mu, en_logvar, output\n",
        "\n",
        "\n",
        "# ============================================================================ #\n",
        "\n",
        "\n",
        "class VAE(nn.Module):\n",
        "\n",
        "    def __init__(self, input_dim, num_classes=10, latent_dim=20):\n",
        "        super(VAE, self).__init__()\n",
        "        self.input_dim = input_dim\n",
        "        self.latent_dim = latent_dim\n",
        "        self.input_dim_flat = 1\n",
        "        for dim in input_dim:\n",
        "            self.input_dim_flat *= dim\n",
        "        self.en_fc1 = nn.Linear(self.input_dim_flat, 400)\n",
        "        self.en_relu1 = nn.ReLU(inplace=True)\n",
        "        self.en_fc2 = nn.Linear(400, 400)\n",
        "        self.en_relu2 = nn.ReLU(inplace=True)\n",
        "        self.en_mu = nn.Linear(400, latent_dim)\n",
        "        self.en_logvar = nn.Linear(400, latent_dim)\n",
        "\n",
        "        self.de_fc1 = nn.Linear(latent_dim, 400)\n",
        "        self.de_relu1 = nn.ReLU(inplace=True)\n",
        "        self.de_fc2 = nn.Linear(400, self.input_dim_flat)\n",
        "\n",
        "    def encode(self, x):\n",
        "        x = x.view(-1, self.input_dim_flat)\n",
        "        x = self.en_relu1(self.en_fc1(x))\n",
        "        x = self.en_relu2(self.en_fc2(x))\n",
        "        en_mu = self.en_mu(x)\n",
        "        # TODO: use tanh activation on logvar if unstable\n",
        "        # en_std = torch.exp(0.5 * x[:, self.latent_dim:])\n",
        "        en_logvar = self.en_logvar(x)\n",
        "        return en_mu, en_logvar\n",
        "\n",
        "    def reparameterize(self, mu, logvar):\n",
        "        std = torch.exp(0.5 * logvar)\n",
        "        eps = torch.randn_like(std)\n",
        "        return mu + eps * std\n",
        "\n",
        "    def decode(self, z):\n",
        "        x = self.de_relu1(self.de_fc1(z))\n",
        "        x = self.de_fc2(x)\n",
        "        out_dim = (z.size(0), ) + self.input_dim\n",
        "        return x.view(out_dim).sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        en_mu, en_logvar = self.encode(x)\n",
        "        z = self.reparameterize(en_mu, en_logvar)\n",
        "        output = self.decode(z)\n",
        "        return en_mu, en_logvar, output\n",
        "\n",
        "\n",
        "# ============================================================================ #\n",
        "\n",
        "\n",
        "class SNNLModel(nn.Module):\n",
        "\n",
        "    def __init__(self, num_classes=10, train_it=False):\n",
        "        super(SNNLModel, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 64, kernel_size=8, stride=2, padding=3)\n",
        "        self.relu1 = nn.ReLU(inplace=True)\n",
        "        self.conv2 = nn.Conv2d(64, 128, kernel_size=6, stride=2, padding=3)\n",
        "        self.relu2 = nn.ReLU(inplace=True)\n",
        "        self.conv3 = nn.Conv2d(128, 128, kernel_size=5, stride=1, padding=0)\n",
        "        self.relu3 = nn.ReLU(inplace=True)\n",
        "        self.fc = nn.Linear(2048, num_classes)\n",
        "\n",
        "        # initialize inverse temperature for each layer\n",
        "        self.it = torch.nn.Parameter(\n",
        "            data=torch.tensor([-4.6, -4.6, -4.6]), requires_grad=train_it)\n",
        "\n",
        "        # set up hook to get representations\n",
        "        self.layers = ['relu1', 'relu2', 'relu3']\n",
        "        self.activations = {}\n",
        "        for name, module in self.named_children():\n",
        "            if name in self.layers:\n",
        "                module.register_forward_hook(self._get_activation(name))\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(\n",
        "                    m.weight, mode='fan_out', nonlinearity='relu')\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "    def _get_activation(self, name):\n",
        "        def hook(model, input, output):\n",
        "            self.activations[name] = output\n",
        "        return hook\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.relu1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.relu2(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.relu3(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "    def loss_function(self, x, y_target, alpha=-1):\n",
        "        \"\"\"soft nearest neighbor loss\"\"\"\n",
        "        snn_loss = torch.zeros(1).cuda()\n",
        "        y_pred = self.forward(x)\n",
        "        for l, layer in enumerate(self.layers):\n",
        "            rep = self.activations[layer]\n",
        "            rep = rep.view(x.size(0), -1)\n",
        "            for i in range(x.size(0)):\n",
        "                mask_same = (y_target[i] == y_target).type(torch.float32)\n",
        "                mask_self = torch.ones(x.size(0)).cuda()\n",
        "                mask_self[i] = 0\n",
        "                dist = ((rep[i] - rep) ** 2).sum(1) * self.it[l].exp()\n",
        "                # dist = ((rep[i] - rep) ** 2).sum(1) * 0.01\n",
        "                # TODO: get nan gradients at\n",
        "                # Function 'MulBackward0' returned nan values in its 1th output.\n",
        "                exp = torch.exp(- torch.min(dist, torch.tensor(50.).cuda()))\n",
        "                # exp = torch.exp(- dist)\n",
        "                snn_loss += torch.log(torch.sum(mask_self * mask_same * exp) /\n",
        "                                      torch.sum(mask_self * exp))\n",
        "\n",
        "        ce_loss = F.cross_entropy(y_pred, y_target)\n",
        "        return y_pred, ce_loss - alpha / x.size(0) * snn_loss\n",
        "\n",
        "\n",
        "# ============================================================================ #\n",
        "\n",
        "\n",
        "class HiddenMixupModel(nn.Module):\n",
        "\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(HiddenMixupModel, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 64, kernel_size=8, stride=2, padding=3)\n",
        "        self.relu1 = nn.ReLU(inplace=True)\n",
        "        self.conv2 = nn.Conv2d(64, 128, kernel_size=6, stride=2, padding=3)\n",
        "        self.relu2 = nn.ReLU(inplace=True)\n",
        "        self.conv3 = nn.Conv2d(128, 128, kernel_size=5, stride=1, padding=0)\n",
        "        self.relu3 = nn.ReLU(inplace=True)\n",
        "        self.fc = nn.Linear(2048, num_classes)\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(\n",
        "                    m.weight, mode='fan_out', nonlinearity='relu')\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "    def forward(self, x, target=None, mixup_hidden=False, mixup_alpha=0.1,\n",
        "                layer_mix=None):\n",
        "\n",
        "        if mixup_hidden:\n",
        "            if layer_mix is None:\n",
        "                # TODO: which layers?\n",
        "                layer_mix = random.randint(0, 4)\n",
        "\n",
        "            if layer_mix == 0:\n",
        "                x, y_a, y_b, lam = self.mixup_data(x, target, mixup_alpha)\n",
        "            x = self.conv1(x)\n",
        "            x = self.relu1(x)\n",
        "\n",
        "            if layer_mix == 1:\n",
        "                x, y_a, y_b, lam = self.mixup_data(x, target, mixup_alpha)\n",
        "            x = self.conv2(x)\n",
        "            x = self.relu2(x)\n",
        "\n",
        "            if layer_mix == 2:\n",
        "                x, y_a, y_b, lam = self.mixup_data(x, target, mixup_alpha)\n",
        "            x = self.conv3(x)\n",
        "            x = self.relu3(x)\n",
        "\n",
        "            if layer_mix == 3:\n",
        "                x, y_a, y_b, lam = self.mixup_data(x, target, mixup_alpha)\n",
        "            x = x.view(x.size(0), -1)\n",
        "            x = self.fc(x)\n",
        "\n",
        "            if layer_mix == 4:\n",
        "                x, y_a, y_b, lam = self.mixup_data(x, target, mixup_alpha)\n",
        "\n",
        "            # lam = torch.tensor(lam).cuda()\n",
        "            # lam = lam.repeat(y_a.size())\n",
        "            return x, y_a, y_b, lam\n",
        "\n",
        "        else:\n",
        "            x = self.conv1(x)\n",
        "            x = self.relu1(x)\n",
        "            x = self.conv2(x)\n",
        "            x = self.relu2(x)\n",
        "            x = self.conv3(x)\n",
        "            x = self.relu3(x)\n",
        "            x = x.view(x.size(0), -1)\n",
        "            x = self.fc(x)\n",
        "            return x\n",
        "\n",
        "    @staticmethod\n",
        "    def loss_function(y_pred, y_a, y_b, lam):\n",
        "        loss = lam * F.cross_entropy(y_pred, y_a) + \\\n",
        "            (1 - lam) * F.cross_entropy(y_pred, y_b)\n",
        "        return loss\n",
        "\n",
        "    @staticmethod\n",
        "    def mixup_data(x, y, alpha):\n",
        "        '''\n",
        "        Compute the mixup data. Return mixed inputs, pairs of targets, and\n",
        "        lambda. Code from\n",
        "        https://github.com/vikasverma1077/manifold_mixup/blob/master/supervised/models/utils.py\n",
        "        '''\n",
        "        if alpha > 0.:\n",
        "            lam = np.random.beta(alpha, alpha)\n",
        "        else:\n",
        "            lam = 1.\n",
        "        index = torch.randperm(x.size(0)).cuda()\n",
        "        mixed_x = lam * x + (1 - lam) * x[index, :]\n",
        "        y_a, y_b = y, y[index]\n",
        "        return mixed_x, y_a, y_b, lam\n",
        "\n",
        "\n",
        "# ============================================================================ #\n",
        "\n",
        "\n",
        "class Autoencoder(nn.Module):\n",
        "\n",
        "    def __init__(self, input_dim, latent_dim=20):\n",
        "        super(Autoencoder, self).__init__()\n",
        "        self.input_dim = input_dim\n",
        "        self.latent_dim = latent_dim\n",
        "        self.input_dim_flat = 1\n",
        "        for dim in input_dim:\n",
        "            self.input_dim_flat *= dim\n",
        "        self.conv1 = nn.Conv2d(1, 64, kernel_size=8, stride=2, padding=3)\n",
        "        self.relu1 = nn.ReLU(inplace=True)\n",
        "        self.conv2 = nn.Conv2d(64, 128, kernel_size=6, stride=2, padding=3)\n",
        "        self.relu2 = nn.ReLU(inplace=True)\n",
        "        self.conv3 = nn.Conv2d(128, 128, kernel_size=5, stride=1, padding=0)\n",
        "        self.relu3 = nn.ReLU(inplace=True)\n",
        "        self.fc = nn.Linear(2048, 400)\n",
        "        self.relu4 = nn.ReLU(inplace=True)\n",
        "        self.latent = nn.Linear(400, latent_dim)\n",
        "\n",
        "        self.de_fc1 = nn.Linear(latent_dim, 400)\n",
        "        self.relu5 = nn.ReLU(inplace=True)\n",
        "        self.de_fc2 = nn.Linear(400, self.input_dim_flat)\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(\n",
        "                    m.weight, mode='fan_out', nonlinearity='relu')\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "    def encode(self, x):\n",
        "        x = self.relu1(self.conv1(x))\n",
        "        x = self.relu2(self.conv2(x))\n",
        "        x = self.relu3(self.conv3(x))\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.relu4(self.fc(x))\n",
        "        x = self.latent(x)\n",
        "        return x\n",
        "\n",
        "    def decode(self, z):\n",
        "        x = self.relu5(self.de_fc1(z))\n",
        "        x = self.de_fc2(x)\n",
        "        out_dim = (z.size(0), ) + self.input_dim\n",
        "        return x.view(out_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        z = self.encode(x)\n",
        "        out = self.decode(z)\n",
        "        return z, out\n",
        "\n",
        "    def loss_function(self, latent, x_recon, inputs, targets):\n",
        "        # MSE loss\n",
        "        return torch.sum((inputs - x_recon) ** 2)\n",
        "\n",
        "\n",
        "# ============================================================================ #\n",
        "\n",
        "\n",
        "class NCAModelV3(nn.Module):\n",
        "\n",
        "    def __init__(self, normalize=False, output_dim=100, num_classes=10,\n",
        "                 init_it=1e-2, train_it=False, train_data=None):\n",
        "        super(NCAModelV3, self).__init__()\n",
        "        self.normalize = normalize\n",
        "        self.output_dim = output_dim\n",
        "        self.num_classes = num_classes\n",
        "        self.conv1 = nn.Conv2d(1, 64, kernel_size=8, stride=2, padding=3)\n",
        "        self.relu1 = nn.ReLU(inplace=True)\n",
        "        self.conv2 = nn.Conv2d(64, 128, kernel_size=6, stride=2, padding=3)\n",
        "        self.relu2 = nn.ReLU(inplace=True)\n",
        "        self.conv3 = nn.Conv2d(128, 128, kernel_size=5, stride=1, padding=0)\n",
        "        self.relu3 = nn.ReLU(inplace=True)\n",
        "        self.fc_ = nn.Linear(2048, output_dim)\n",
        "        # self.fc = nn.Identity()\n",
        "        self.fc = nn.Sigmoid()\n",
        "\n",
        "        # initialize inverse temperature for each layer\n",
        "        self.log_it = torch.nn.Parameter(\n",
        "            data=torch.tensor(np.log(init_it)), requires_grad=train_it)\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(\n",
        "                    m.weight, mode='fan_out', nonlinearity='relu')\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "        self.train_data = train_data\n",
        "        self.train_rep = None\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.relu1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.relu2(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.relu3(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc_(x)\n",
        "        if self.normalize:\n",
        "            x = F.normalize(x, p=2, dim=1)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "    def forward_adv(self, x_orig, y_target, params):\n",
        "        \"\"\"\n",
        "        \"\"\"\n",
        "        epsilon = params['epsilon']\n",
        "        step_size = params['step_size']\n",
        "        num_steps = params['num_steps']\n",
        "        rand = params['random_start']\n",
        "\n",
        "        # training samples that we want to query against should not be perturbed\n",
        "        # so we keep an extra copy and detach it from gradient computation\n",
        "        with torch.no_grad():\n",
        "            outputs_orig = self.forward(x_orig).detach()\n",
        "\n",
        "        x = x_orig.clone()\n",
        "        if rand:\n",
        "            noise = torch.zeros_like(x).normal_(0, 1).view(x.size(0), -1)\n",
        "            x += noise.renorm(2, 0, epsilon).view(x.size())\n",
        "\n",
        "        for _ in range(num_steps):\n",
        "            x.requires_grad_()\n",
        "            with torch.enable_grad():\n",
        "                outputs = self.forward(x)\n",
        "                p_target = self.get_prob(\n",
        "                    outputs, y_target, x_orig=outputs_orig)\n",
        "                loss = - torch.log(p_target).sum()\n",
        "            grad = torch.autograd.grad(loss, x)[0].detach()\n",
        "            grad_norm = grad.view(x.size(0), -1).norm(2, 1).clamp(1e-5, 1e9)\n",
        "            delta = step_size * grad / grad_norm.view(x.size(0), 1, 1, 1)\n",
        "            x = x.detach() + delta\n",
        "            diff = (x - x_orig).view(x.size(0), -1).renorm(2, 0, epsilon)\n",
        "            x = diff.view(x.size()) + x_orig\n",
        "            x.clamp_(0, 1)\n",
        "\n",
        "        return outputs_orig, self.forward(x)\n",
        "\n",
        "    def get_prob(self, x, y_target, x_orig=None):\n",
        "        \"\"\"\n",
        "        If x_orig is given, compute distance w.r.t. x_orig instead of samples\n",
        "        in the same batch (x). It is intended to be used with adversarial\n",
        "        training.\n",
        "        \"\"\"\n",
        "        if x_orig is not None:\n",
        "            assert x.size(0) == x_orig.size(0)\n",
        "\n",
        "        batch_size = x.size(0)\n",
        "        device = x.device\n",
        "        x = x.view(batch_size, -1)\n",
        "        if x_orig is not None:\n",
        "            x_orig = x_orig.view(batch_size, -1)\n",
        "            x_repeat = x_orig.repeat(batch_size, 1, 1).transpose(0, 1)\n",
        "        else:\n",
        "            x_repeat = x.repeat(batch_size, 1, 1).transpose(0, 1)\n",
        "        dist = ((x_repeat - x) ** 2).sum(2) * self.log_it.exp()\n",
        "        exp = torch.exp(- dist.clamp(- 50, 50))\n",
        "        mask_not_self = 1 - torch.eye(batch_size, device=device)\n",
        "        mask_same = (y_target.repeat(batch_size, 1).transpose(0, 1) ==\n",
        "                     y_target).float()\n",
        "        p_target = ((mask_not_self * mask_same * exp).sum(0) /\n",
        "                    (mask_not_self * exp).sum(0))\n",
        "        # p_target = (mask_same * exp).sum(0) / exp.sum(0)\n",
        "        # Prevent the case where there's only one sample in the batch from a\n",
        "        # certain clss, resulting in p_target being 0\n",
        "        p_target = torch.max(p_target, torch.tensor(1e-30).to(device))\n",
        "\n",
        "        return p_target\n",
        "\n",
        "    def loss_function(self, output, y_target, orig=None):\n",
        "        \"\"\"soft nearest neighbor loss\"\"\"\n",
        "        p_target = self.get_prob(output, y_target, x_orig=orig)\n",
        "        # y_pred = p_target.max(1)\n",
        "        loss = - torch.log(p_target)\n",
        "        return loss.mean()\n",
        "\n",
        "\n",
        "    def get_train_rep(self, batch_size=200, requires_grad=False):\n",
        "        \"\"\"update self.train_rep by running it through the current model\"\"\"\n",
        "        if self.train_data is None:\n",
        "            raise ValueError(\n",
        "                'Cannot compute train rep as train data is not provided.')\n",
        "        x_train, _ = self.train_data\n",
        "        device = self._get_device()\n",
        "        train_rep = torch.zeros((x_train.size(0), self.output_dim),\n",
        "                                device=device, requires_grad=requires_grad)\n",
        "        num_batches = np.ceil(x_train.size(0) // batch_size).astype(np.int32)\n",
        "        with torch.set_grad_enabled(requires_grad):\n",
        "            for i in range(num_batches):\n",
        "                start = i * batch_size\n",
        "                end = (i + 1) * batch_size\n",
        "                train_rep[start:end] = self.forward(\n",
        "                    x_train[start:end].to(device))\n",
        "        return train_rep\n",
        "\n",
        "    def recompute_train_rep(self):\n",
        "        self.train_rep = self.get_train_rep(requires_grad=False)\n",
        "\n",
        "    def compute_logits(self, x, recompute_train_rep=False, requires_grad=False,\n",
        "                       from_outputs=False):\n",
        "\n",
        "        if recompute_train_rep:\n",
        "            self.recompute_train_rep()\n",
        "        _, y_train = self.train_data\n",
        "        device = self._get_device()\n",
        "        # logits = torch.zeros((x.size(0), self.num_classes), device=x.device,\n",
        "        #                      requires_grad=requires_grad)\n",
        "        logits = []\n",
        "        with torch.set_grad_enabled(requires_grad):\n",
        "            if not from_outputs:\n",
        "                rep = self.forward(x.to(device))\n",
        "            else:\n",
        "                rep = x\n",
        "            dist = ((self.train_rep - rep.unsqueeze(1)) ** 2).sum(2)\n",
        "            exp = torch.exp(- dist.clamp(- 50, 50) * self.log_it.exp())\n",
        "            for j in range(self.num_classes):\n",
        "                mask_j = (y_train == j).float().to(device)\n",
        "                logits.append(\n",
        "                    ((mask_j * exp).sum(1) / exp.sum(1)).unsqueeze(-1))\n",
        "        return torch.cat(logits, dim=-1)\n",
        "\n",
        "    def _get_device(self):\n",
        "        return next(self.parameters()).device\n",
        "\n",
        "\n",
        "class WeightedNCA(NCAModelV3):\n",
        "    def __init__(self, normalize=False, output_dim=100, num_classes=10,\n",
        "                 init_it=1e-2, train_it=False, train_data=None):\n",
        "        super().__init__(normalize=normalize, output_dim=output_dim,\n",
        "                         num_classes=num_classes, init_it=init_it,\n",
        "                         train_it=train_it, train_data=train_data)\n",
        "        self.weights = torch.nn.Parameter(\n",
        "            data=torch.ones(len(self.train_data[0])), requires_grad=True)\n",
        "\n",
        "    def compute_logits(self, x, recompute_train_rep=False, requires_grad=False,\n",
        "                       from_outputs=False):\n",
        "\n",
        "        if recompute_train_rep:\n",
        "            self.recompute_train_rep()\n",
        "        _, y_train = self.train_data\n",
        "        device = self._get_device()\n",
        "        \n",
        "        logits = []\n",
        "        with torch.set_grad_enabled(requires_grad):\n",
        "            if not from_outputs:\n",
        "                rep = self.forward(x.to(device))\n",
        "            else:\n",
        "                rep = x\n",
        "            dist = ((self.train_rep - rep.unsqueeze(1)) ** 2).sum(2)\n",
        "            exp = torch.exp(- dist.clamp(- 50, 50) * self.log_it.exp())\n",
        "            exp *= self.weights.sigmoid()\n",
        "            for j in range(self.num_classes):\n",
        "                mask_j = (y_train == j).float().to(device)\n",
        "                logits.append(\n",
        "                    ((mask_j * exp).sum(1) / exp.sum(1)).unsqueeze(-1))\n",
        "        return torch.cat(logits, dim=-1)\n",
        "\n",
        "\n",
        "class SoftLabelNCA(NCAModelV3):\n",
        "    def __init__(self, ys_train, normalize=False, output_dim=100, num_classes=10,\n",
        "                 init_it=1e-2, train_it=False, train_data=None):\n",
        "        super().__init__(normalize=normalize, output_dim=output_dim,\n",
        "                         num_classes=num_classes, init_it=init_it,\n",
        "                         train_it=train_it, train_data=train_data)\n",
        "        self.ys_train = ys_train\n",
        "\n",
        "    def recompute_ys_train(self, k):\n",
        "        self.recompute_train_rep()\n",
        "        y_train = self.train_data[1]\n",
        "        for i in range(len(y_train)):\n",
        "            dist = ((self.train_rep[i] - self.train_rep) ** 2).sum(1)\n",
        "            nb = torch.topk(dist, k, largest=False)[1]\n",
        "            ys = np.bincount(\n",
        "                y_train[nb].numpy(), minlength=self.num_classes) / k\n",
        "            self.ys_train[i] = torch.tensor(ys, device='cuda').float()\n",
        "\n",
        "    def compute_logits(self, x, recompute_train_rep=False, requires_grad=False,\n",
        "                       from_outputs=False):\n",
        "\n",
        "        if recompute_train_rep:\n",
        "            self.recompute_train_rep()\n",
        "        _, y_train = self.train_data\n",
        "        device = self._get_device()\n",
        "        # logits = torch.zeros((x.size(0), self.num_classes), device=x.device,\n",
        "        #                      requires_grad=requires_grad)\n",
        "        logits = []\n",
        "        with torch.set_grad_enabled(requires_grad):\n",
        "            if not from_outputs:\n",
        "                rep = self.forward(x.to(device))\n",
        "            else:\n",
        "                rep = x\n",
        "            dist = ((self.train_rep - rep.unsqueeze(1)) ** 2).sum(2)\n",
        "            exp = torch.exp(- (dist * self.log_it.exp()).clamp(- 50, 50))\n",
        "            probs = exp @ self.ys_train\n",
        "            logits = probs / exp.sum(1).unsqueeze(1)\n",
        "        return logits"
      ],
      "metadata": {
        "id": "lk3TGE7S1p9E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Dataset_utils**\n"
      ],
      "metadata": {
        "id": "_nqIY1YbyVZo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def rotate_img(img, rot):\n",
        "    if rot == 0:  # 0 degrees rotation\n",
        "        return img\n",
        "    elif rot == 90:  # 90 degrees rotation\n",
        "        return np.flipud(np.transpose(img, (1, 0, 2)))\n",
        "    elif rot == 180:  # 90 degrees rotation\n",
        "        return np.fliplr(np.flipud(img))\n",
        "    elif rot == 270:  # 270 degrees rotation / or -90\n",
        "        return np.transpose(np.flipud(img), (1, 0, 2))\n",
        "    else:\n",
        "        raise ValueError('rotation should be 0, 90, 180, or 270 degrees')\n",
        "\n",
        "\n",
        "class RotateDataset(Dataset):\n",
        "\n",
        "    def __init__(self, dataset):\n",
        "        self.dataset = dataset\n",
        "        self.transform = transforms.Compose([\n",
        "            transforms.ToTensor()\n",
        "        ])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img = self.dataset[idx]\n",
        "        rotated_imgs = [\n",
        "            self.transform(img),\n",
        "            self.transform(rotate_img(img, 90).copy()),\n",
        "            self.transform(rotate_img(img, 180).copy()),\n",
        "            self.transform(rotate_img(img, 270).copy())\n",
        "        ]\n",
        "        rotation_labels = torch.LongTensor([0, 1, 2, 3])\n",
        "        return torch.stack(rotated_imgs, dim=0), rotation_labels\n",
        "\n",
        "\n",
        "def load_mnist(batch_size,\n",
        "               data_dir='./data',\n",
        "               val_size=0.1,\n",
        "               shuffle=True,\n",
        "               seed=1):\n",
        "    \"\"\"Load MNIST data into train/val/test data loader\"\"\"\n",
        "\n",
        "    num_workers = 4\n",
        "\n",
        "    (x_train, y_train), (x_valid, y_valid), (x_test, y_test) = load_mnist_all(\n",
        "        data_dir=data_dir, val_size=val_size, shuffle=shuffle, seed=seed)\n",
        "\n",
        "    trainset = torch.utils.data.TensorDataset(x_train, y_train)\n",
        "    validset = torch.utils.data.TensorDataset(x_valid, y_valid)\n",
        "    testset = torch.utils.data.TensorDataset(x_test, y_test)\n",
        "    trainloader = torch.utils.data.DataLoader(\n",
        "        trainset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
        "    validloader = torch.utils.data.DataLoader(\n",
        "        validset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
        "    testloader = torch.utils.data.DataLoader(\n",
        "        testset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
        "\n",
        "    return trainloader, validloader, testloader\n",
        "\n",
        "\n",
        "def load_mnist_all(data_dir='./data', val_size=0.1, shuffle=True, seed=1):\n",
        "    \"\"\"Load entire MNIST dataset into tensor\"\"\"\n",
        "\n",
        "    transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "    ])\n",
        "\n",
        "    trainset = torchvision.datasets.MNIST(\n",
        "        root=data_dir, train=True, download=True, transform=transform)\n",
        "    testset = torchvision.datasets.MNIST(\n",
        "        root=data_dir, train=False, download=True, transform=transform)\n",
        "\n",
        "    trainloader = torch.utils.data.DataLoader(\n",
        "        trainset, batch_size=len(trainset), shuffle=False)\n",
        "    testloader = torch.utils.data.DataLoader(\n",
        "        testset, batch_size=len(testset), shuffle=False)\n",
        "\n",
        "    x, y = next(iter(trainloader))\n",
        "    x_test, y_test = next(iter(testloader))\n",
        "\n",
        "    if val_size > 0:\n",
        "        np.random.seed(seed)\n",
        "        x_train, x_valid, y_train, y_valid = train_test_split(\n",
        "            x.numpy(), y.numpy(), test_size=val_size, shuffle=shuffle,\n",
        "            random_state=seed, stratify=y)\n",
        "        return ((torch.tensor(x_train), torch.tensor(y_train)),\n",
        "                (torch.tensor(x_valid), torch.tensor(y_valid)),\n",
        "                (x_test, y_test))\n",
        "    else:\n",
        "        return ((x, y), (None, None), (x_test, y_test))\n",
        "\n",
        "\n",
        "def load_mnist_rot(batch_size, data_dir='./data', val_size=0.1, shuffle=True,\n",
        "                   seed=1):\n",
        "\n",
        "    (x_train, _), (x_valid, _), (x_test, _) = load_mnist_all(\n",
        "        data_dir, val_size=val_size, seed=seed)\n",
        "\n",
        "    traindataset = RotateDataset(x_train.numpy().transpose(0, 2, 3, 1))\n",
        "    trainloader = torch.utils.data.DataLoader(\n",
        "        traindataset, batch_size=batch_size, shuffle=shuffle, num_workers=4)\n",
        "\n",
        "    validdataset = RotateDataset(x_valid.numpy().transpose(0, 2, 3, 1))\n",
        "    validloader = torch.utils.data.DataLoader(\n",
        "        validdataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
        "\n",
        "    testdataset = RotateDataset(x_test.numpy().transpose(0, 2, 3, 1))\n",
        "    testloader = torch.utils.data.DataLoader(\n",
        "        testdataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
        "\n",
        "    return trainloader, validloader, testloader\n",
        "\n",
        "\n",
        "def load_cifar10(batch_size,\n",
        "                 data_dir='./data',\n",
        "                 val_size=0.1,\n",
        "                 normalize=True,\n",
        "                 augment=True,\n",
        "                 shuffle=True,\n",
        "                 seed=1):\n",
        "    \"\"\"Load CIFAR-10 data into train/val/test data loader\"\"\"\n",
        "\n",
        "    mean = (0.4914, 0.4822, 0.4465)\n",
        "    std = (0.2023, 0.1994, 0.2010)\n",
        "    num_workers = 4\n",
        "\n",
        "    transform = transforms.Compose([\n",
        "        transforms.ToTensor()\n",
        "    ])\n",
        "\n",
        "    if augment:\n",
        "        transform_train = transforms.Compose([\n",
        "            transforms.RandomCrop(32, padding=4),\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.RandomAffine(\n",
        "                5, translate=(0.1, 0.1), scale=(0.9, 1.1), shear=5),\n",
        "            transforms.ColorJitter(brightness=0.1),\n",
        "            transforms.ToTensor()\n",
        "        ])\n",
        "    else:\n",
        "        transform_train = transform\n",
        "\n",
        "    if normalize:\n",
        "        transform = transforms.Compose([\n",
        "            transform,\n",
        "            transforms.Normalize(mean, std)\n",
        "        ])\n",
        "        transform_train = transforms.Compose([\n",
        "            transform_train,\n",
        "            transforms.Normalize(mean, std)\n",
        "        ])\n",
        "\n",
        "    trainset = torchvision.datasets.CIFAR10(\n",
        "        root=data_dir, train=True, download=True, transform=transform_train)\n",
        "    validset = torchvision.datasets.CIFAR10(\n",
        "        root=data_dir, train=True, download=True, transform=transform)\n",
        "    testset = torchvision.datasets.CIFAR10(\n",
        "        root=data_dir, train=False, download=True, transform=transform)\n",
        "\n",
        "    # Random split train and validation sets\n",
        "    num_train = len(trainset)\n",
        "    indices = list(range(num_train))\n",
        "    split = int(np.floor(val_size * num_train))\n",
        "\n",
        "    if shuffle:\n",
        "        np.random.seed(seed)\n",
        "        np.random.shuffle(indices)\n",
        "\n",
        "    train_idx, valid_idx = indices[split:], indices[:split]\n",
        "    train_sampler = SubsetRandomSampler(train_idx)\n",
        "    valid_sampler = SubsetRandomSampler(valid_idx)\n",
        "\n",
        "    trainloader = torch.utils.data.DataLoader(\n",
        "        trainset, batch_size=batch_size, sampler=train_sampler,\n",
        "        num_workers=num_workers)\n",
        "    validloader = torch.utils.data.DataLoader(\n",
        "        validset, batch_size=batch_size, sampler=valid_sampler,\n",
        "        num_workers=num_workers)\n",
        "    testloader = torch.utils.data.DataLoader(\n",
        "        testset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
        "\n",
        "    return trainloader, validloader, testloader\n",
        "\n",
        "\n",
        "def load_cifar10_all(data_dir='./data', val_size=0.1, shuffle=True, seed=1):\n",
        "    \"\"\"Load entire CIFAR-10 dataset into tensor\"\"\"\n",
        "\n",
        "    transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "    ])\n",
        "\n",
        "    trainset = torchvision.datasets.CIFAR10(\n",
        "        root=data_dir, train=True, download=True, transform=transform)\n",
        "    validset = torchvision.datasets.CIFAR10(\n",
        "        root=data_dir, train=True, download=True, transform=transform)\n",
        "    testset = torchvision.datasets.CIFAR10(\n",
        "        root=data_dir, train=False, download=True, transform=transform)\n",
        "\n",
        "    # Random split train and validation sets\n",
        "    num_train = len(trainset)\n",
        "    indices = list(range(num_train))\n",
        "    split = int(np.floor(val_size * num_train))\n",
        "\n",
        "    if shuffle:\n",
        "        np.random.seed(seed)\n",
        "        np.random.shuffle(indices)\n",
        "\n",
        "    train_idx, valid_idx = indices[split:], indices[:split]\n",
        "    train_sampler = SubsetRandomSampler(train_idx)\n",
        "    valid_sampler = SubsetRandomSampler(valid_idx)\n",
        "\n",
        "    trainloader = torch.utils.data.DataLoader(\n",
        "        trainset, batch_size=(num_train - split), sampler=train_sampler)\n",
        "    validloader = torch.utils.data.DataLoader(\n",
        "        validset, batch_size=split, sampler=valid_sampler)\n",
        "    testloader = torch.utils.data.DataLoader(\n",
        "        testset, batch_size=len(testset), shuffle=False)\n",
        "\n",
        "    x_train = next(iter(trainloader))\n",
        "    x_valid = next(iter(validloader))\n",
        "    x_test = next(iter(testloader))\n",
        "\n",
        "    return x_train, x_valid, x_test\n",
        "\n",
        "\n",
        "def load_cifar10_rot(batch_size, data_dir='./data', val_size=0.1, shuffle=True,\n",
        "                     seed=1):\n",
        "\n",
        "    (x_train, _), (x_valid, _), (x_test, _) = load_cifar10_all(\n",
        "        data_dir, val_size=val_size, seed=seed)\n",
        "\n",
        "    traindataset = RotateDataset(x_train.numpy().transpose(0, 2, 3, 1))\n",
        "    trainloader = torch.utils.data.DataLoader(\n",
        "        traindataset, batch_size=batch_size, shuffle=shuffle, num_workers=4)\n",
        "\n",
        "    validdataset = RotateDataset(x_valid.numpy().transpose(0, 2, 3, 1))\n",
        "    validloader = torch.utils.data.DataLoader(\n",
        "        validdataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
        "\n",
        "    testdataset = RotateDataset(x_test.numpy().transpose(0, 2, 3, 1))\n",
        "    testloader = torch.utils.data.DataLoader(\n",
        "        testdataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
        "\n",
        "    return trainloader, validloader, testloader\n",
        "\n",
        "\n",
        "def load_gtsrb(data_dir='./data', gray=False, train_file_name=None):\n",
        "    \"\"\"\n",
        "    Load GTSRB data as a (datasize) x (channels) x (height) x (width) numpy\n",
        "    matrix. Each pixel is rescaled to lie in [0,1].\n",
        "    \"\"\"\n",
        "\n",
        "    def load_pickled_data(file, columns):\n",
        "        \"\"\"\n",
        "        Loads pickled training and test data.\n",
        "        Parameters\n",
        "        ----------\n",
        "        file : string\n",
        "            Name of the pickle file.\n",
        "        columns : list of str\n",
        "            List of columns in pickled data we're interested in.\n",
        "        Returns\n",
        "        -------\n",
        "        A tuple of datasets for given columns.\n",
        "        \"\"\"\n",
        "\n",
        "        with open(file, mode='rb') as f:\n",
        "            dataset = pickle.load(f)\n",
        "        return tuple(map(lambda c: dataset[c], columns))\n",
        "\n",
        "    def preprocess(x, gray):\n",
        "        \"\"\"\n",
        "        Preprocess dataset: turn images into grayscale if specified, normalize\n",
        "        input space to [0,1], reshape array to appropriate shape for NN model\n",
        "        \"\"\"\n",
        "\n",
        "        if not gray:\n",
        "            # Scale features to be in [0, 1]\n",
        "            x = (x / 255.).astype(np.float32)\n",
        "        else:\n",
        "            # Convert to grayscale, e.g. single Y channel\n",
        "            x = 0.299 * x[:, :, :, 0] + 0.587 * x[:, :, :, 1] + \\\n",
        "                0.114 * x[:, :, :, 2]\n",
        "            # Scale features to be in [0, 1]\n",
        "            x = (x / 255.).astype(np.float32)\n",
        "            x = x[:, :, :, np.newaxis]\n",
        "        return x\n",
        "\n",
        "    # Load pickle dataset\n",
        "    if train_file_name is None:\n",
        "        x_train, y_train = load_pickled_data(\n",
        "            data_dir + 'train.p', ['features', 'labels'])\n",
        "    else:\n",
        "        x_train, y_train = load_pickled_data(\n",
        "            data_dir + train_file_name, ['features', 'labels'])\n",
        "    x_val, y_val = load_pickled_data(\n",
        "        data_dir + 'valid.p', ['features', 'labels'])\n",
        "    x_test, y_test = load_pickled_data(\n",
        "        data_dir + 'test.p', ['features', 'labels'])\n",
        "\n",
        "    # Preprocess loaded data\n",
        "    x_train = preprocess(x_train, gray)\n",
        "    x_val = preprocess(x_val, gray)\n",
        "    x_test = preprocess(x_test, gray)\n",
        "    return x_train, y_train, x_val, y_val, x_test, y_test\n",
        "\n",
        "\n",
        "class GtsrbDataset(torch.utils.data.Dataset):\n",
        "\n",
        "    def __init__(self, x_np, y_np, mean=None, std=None, augment=False):\n",
        "\n",
        "        self.x_pil = [Image.fromarray(\n",
        "            (x * 255).astype(np.uint8)) for x in x_np]\n",
        "        self.y_np = y_np.astype(np.int64)\n",
        "\n",
        "        if mean is None:\n",
        "            mean = (0, 0, 0)\n",
        "            std = (1, 1, 1)\n",
        "\n",
        "        if augment:\n",
        "            self.transform = transforms.Compose([\n",
        "                transforms.RandomCrop(32, padding=4, padding_mode='edge'),\n",
        "                transforms.RandomAffine(\n",
        "                    5, translate=(0.1, 0.1), scale=(0.9, 1.1), shear=5),\n",
        "                transforms.ColorJitter(brightness=0.1),\n",
        "                transforms.ToTensor(),\n",
        "                # transforms.Normalize(mean, std),\n",
        "            ])\n",
        "        else:\n",
        "            self.transform = transforms.Compose([\n",
        "                transforms.ToTensor(),\n",
        "                # transforms.Normalize(mean, std),\n",
        "            ])\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        # apply the transformations and return tensors\n",
        "        return self.transform(self.x_pil[index]), self.y_np[index]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.x_pil)\n",
        "\n",
        "\n",
        "def load_gtsrb_dataloader(data_dir, batch_size, num_workers=4):\n",
        "\n",
        "    x_train, y_train, x_val, y_val, x_test, y_test = load_gtsrb(\n",
        "        data_dir=data_dir)\n",
        "\n",
        "    # Standardization\n",
        "    mean = np.mean(x_train, (0, 1, 2))\n",
        "    std = np.std(x_train, (0, 1, 2))\n",
        "\n",
        "    trainset = GtsrbDataset(x_train, y_train, mean, std, augment=True)\n",
        "    validset = GtsrbDataset(x_val, y_val, mean, std, augment=False)\n",
        "    testset = GtsrbDataset(x_test, y_test, mean, std, augment=False)\n",
        "\n",
        "    trainloader = torch.utils.data.DataLoader(\n",
        "        trainset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
        "    validloader = torch.utils.data.DataLoader(\n",
        "        validset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
        "    testloader = torch.utils.data.DataLoader(\n",
        "        testset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
        "\n",
        "    return trainloader, validloader, testloader"
      ],
      "metadata": {
        "id": "Gg5PR3bOyqzA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **DKNN**"
      ],
      "metadata": {
        "id": "RhfI-AJoAMuO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Define Deep k-Nearest Neighbor object\n",
        "'''\n",
        "\n",
        "\n",
        "class DKNNL2(object):\n",
        "    \"\"\"\n",
        "    An object that we use to create and store a deep k-nearest neighbor (DkNN)\n",
        "    that uses Euclidean distance as a metric.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, model, x_train, y_train, x_cal, y_cal, layers, k=75,\n",
        "                 num_classes=10, ys_train=None, cosine=False, device='cuda'):\n",
        "        \"\"\"\n",
        "        Parameters\n",
        "        ----------\n",
        "        model : torch.nn.Module\n",
        "            neural network model that extracts the representations\n",
        "        x_train : torch.tensor\n",
        "            a tensor of training samples with shape (num_train_samples, ) +\n",
        "            input_shape\n",
        "        y_train : torch.tensor\n",
        "            a tensor of labels corresponding to samples in x_train with shape\n",
        "            (num_train_samples, )\n",
        "        x_cal : torch.tensor\n",
        "            a tensor of calibrating samples used to calibrate credibility score\n",
        "            as described in DkNN paper (Papernot & McDaniel '18)\n",
        "        y_cal : torch.tensor\n",
        "            a tensor of labels corresponding to x_cal\n",
        "        layers : list of str\n",
        "            a list of layer names that are used in DkNN\n",
        "        k : int, optional\n",
        "            the number of neighbors to consider, i.e. k in the kNN part\n",
        "            (default is 75)\n",
        "        num_classes : int, optional\n",
        "            the number of classes (default is 10)\n",
        "        ys_train : torch.tensor, optional\n",
        "            specify soft labels for training samples. Must have shape\n",
        "            (num_train_samples, num_classes). (default is None)\n",
        "        cosine : bool, optional\n",
        "            If True, use cosine distance. Else use Euclidean distance.\n",
        "            (default is False)\n",
        "        device : str, optional\n",
        "            name of the device model is on (default is 'cuda')\n",
        "        \"\"\"\n",
        "        self.model = model\n",
        "        self.cosine = cosine\n",
        "        self.x_train = x_train\n",
        "        self.y_train = y_train\n",
        "        self.ys_train = ys_train\n",
        "        self.layers = layers\n",
        "        self.k = k\n",
        "        self.num_classes = num_classes\n",
        "        self.device = device\n",
        "        self.indices = []\n",
        "        self.activations = {}\n",
        "\n",
        "        # register hook to get representations\n",
        "        layer_count = 0\n",
        "        for name, module in self.model.named_children():\n",
        "            # if layer name is one of the names specified in self.layers,\n",
        "            # register a hook to extract the activation at every forward pass\n",
        "            if name in self.layers:\n",
        "                module.register_forward_hook(self._get_activation(name))\n",
        "                layer_count += 1\n",
        "        assert layer_count == len(layers)\n",
        "        reps = self.get_activations(x_train, requires_grad=False)\n",
        "\n",
        "        for layer in layers:\n",
        "            # build faiss index from the activations by layer\n",
        "            index = self._build_index(reps[layer].cpu())\n",
        "            self.indices.append(index)\n",
        "\n",
        "        # set up calibration for credibility score\n",
        "        y_pred = self.classify(x_cal)\n",
        "        self.A = np.zeros((x_cal.size(0), )) + self.k * len(self.layers)\n",
        "        for i, (y_c, y_p) in enumerate(zip(y_cal, y_pred)):\n",
        "            self.A[i] -= y_p[y_c]\n",
        "\n",
        "    def _get_activation(self, name):\n",
        "        \"\"\"Hook used to get activation from specified layer name\n",
        "        Parameters\n",
        "        ----------\n",
        "        name : str\n",
        "            name of the layer to collect the activations\n",
        "        Returns\n",
        "        -------\n",
        "        hook\n",
        "            the hook function\n",
        "        \"\"\"\n",
        "        def hook(model, input, output):\n",
        "            self.activations[name] = output\n",
        "        return hook\n",
        "\n",
        "    def _build_index(self, xb):\n",
        "        \"\"\"Build faiss index from a given set of samples\n",
        "        Parameters\n",
        "        ----------\n",
        "        xb : torch.tensor\n",
        "            tensor of samples to build the search index, shape is\n",
        "            (num_samples, dim)\n",
        "        Returns\n",
        "        -------\n",
        "        index\n",
        "            faiss index built on the given samples\n",
        "        \"\"\"\n",
        "\n",
        "        d = xb.size(-1)\n",
        "        # brute-force search on GPU (GPU generally doesn't have enough memory)\n",
        "        # res = faiss.StandardGpuResources()\n",
        "        # index = faiss.GpuIndexFlatIP(res, d)\n",
        "\n",
        "        # brute-force search on CPU\n",
        "        index = faiss.IndexFlatL2(d)\n",
        "\n",
        "        index.add(xb.detach().cpu().numpy())\n",
        "        return index\n",
        "\n",
        "    def get_activations(self, x, batch_size=500, requires_grad=True,\n",
        "                        device=None):\n",
        "        \"\"\"Get activations at each layer in self.layers\n",
        "        Parameters\n",
        "        ----------\n",
        "        x : torch.tensor\n",
        "            tensor of input samples, shape = (num_samples, ) + input_shape\n",
        "        batch_size : int, optional\n",
        "            batch size (Default is 500)\n",
        "        requires_grad : bool, optional\n",
        "            whether or not to require gradients on the activations\n",
        "            (Default is False)\n",
        "        device : str\n",
        "            name of the device the model is on (Default is None)\n",
        "        Returns\n",
        "        -------\n",
        "        activations : dict\n",
        "            dict of torch.tensor containing activations\n",
        "        \"\"\"\n",
        "        if device is None:\n",
        "            device = self.device\n",
        "\n",
        "        # first run through to set an empty tensor of an appropriate size\n",
        "        with torch.no_grad():\n",
        "            num_total = x.size(0)\n",
        "            num_batches = int(np.ceil(num_total / batch_size))\n",
        "            activations = {}\n",
        "            self.model(x[0:1].to(device))\n",
        "            for layer in self.layers:\n",
        "                size = torch.tensor(self.activations[layer].size()[1:]).prod()\n",
        "                activations[layer] = torch.empty((num_total, size),\n",
        "                                                 dtype=torch.float32,\n",
        "                                                 device=device,\n",
        "                                                 requires_grad=False)\n",
        "\n",
        "        with torch.set_grad_enabled(requires_grad):\n",
        "            for i in range(num_batches):\n",
        "                begin, end = i * batch_size, (i + 1) * batch_size\n",
        "                # run a forward pass, the attribute self.activations get set\n",
        "                # to activations of the current batch\n",
        "                self.model(x[begin:end].to(device))\n",
        "                # copy the extracted activations to the dictionary of\n",
        "                # tensor allocated earlier\n",
        "                for layer in self.layers:\n",
        "                    act = self.activations[layer]\n",
        "                    act = act.view(act.size(0), -1)\n",
        "                    if self.cosine:\n",
        "                        act = F.normalize(act, 2, 1)\n",
        "                    activations[layer][begin:end] = act\n",
        "\n",
        "            return activations\n",
        "\n",
        "    def get_neighbors(self, x, k=None, layers=None):\n",
        "        \"\"\"Find k neighbors of x at specified layers\n",
        "        Parameters\n",
        "        ----------\n",
        "        x : torch.tensor\n",
        "            samples to query, shape (num_samples, ) + input_shape\n",
        "        k : int, optional\n",
        "            number of neighbors (Default is self.k)\n",
        "        layers : list of str\n",
        "            list of layer names to find neighbors on (Default is self.layers)\n",
        "        Returns\n",
        "        -------\n",
        "        output : list\n",
        "            list of len(layers) tuples of distances and indices of k neighbors\n",
        "        \"\"\"\n",
        "        if k is None:\n",
        "            k = self.k\n",
        "        if layers is None:\n",
        "            layers = self.layers\n",
        "\n",
        "        output = []\n",
        "        reps = self.get_activations(x, requires_grad=False)\n",
        "        for layer, index in zip(self.layers, self.indices):\n",
        "            if layer in layers:\n",
        "                rep = reps[layer].detach().cpu().numpy()\n",
        "                D, I = index.search(rep, k)\n",
        "                # D, I = search_index_pytorch(index, reps[layer], k)\n",
        "                # uncomment when using GPU\n",
        "                # res.syncDefaultStreamCurrentDevice()\n",
        "                output.append((D, I))\n",
        "        return output\n",
        "\n",
        "    def classify(self, x, k=None):\n",
        "        \"\"\"Find number of k-nearest neighbors in each class\n",
        "        Arguments\n",
        "        ---------\n",
        "        x : torch.tensor\n",
        "            samples to query, shape is (num_samples, ) + input_shape\n",
        "        k : int, optional\n",
        "            number of neighbors to check (Default is None)\n",
        "        Returns\n",
        "        -------\n",
        "        class_counts : np.array\n",
        "            array of numbers of neighbors in each class, shape is\n",
        "            (num_samples, self.num_classes)\n",
        "        \"\"\"\n",
        "        nb = self.get_neighbors(x, k=k)\n",
        "        class_counts = np.zeros((x.size(0), self.num_classes))\n",
        "        for (_, I) in nb:\n",
        "            y_pred = self.y_train.cpu().numpy()[I]\n",
        "            for i in range(x.size(0)):\n",
        "                class_counts[i] += np.bincount(\n",
        "                    y_pred[i], minlength=self.num_classes)\n",
        "        return class_counts\n",
        "\n",
        "    def classify_soft(self, x, k=None):\n",
        "        \"\"\"Use soft lable for classification\n",
        "        Arguments\n",
        "        ---------\n",
        "        x : torch.tensor\n",
        "            samples to query, shape is (num_samples, ) + input_shape\n",
        "        k : int, optional\n",
        "            number of neighbors to check (Default is None)\n",
        "        Returns\n",
        "        -------\n",
        "        class_counts : np.array\n",
        "            array of numbers of neighbors in each class, shape is\n",
        "            (num_samples, self.num_classes)\n",
        "        \"\"\"\n",
        "        nb = self.get_neighbors(x, k=k)\n",
        "        ys = np.zeros((x.size(0), self.num_classes))\n",
        "        for (_, I) in nb:\n",
        "            for i in range(x.size(0)):\n",
        "                ys[i] += self.ys_train.cpu().numpy()[I[i]].mean(0)\n",
        "        return ys\n",
        "\n",
        "    def predict(self, x):\n",
        "        \"\"\"Predict label of single sample x\"\"\"\n",
        "        return self.classify(x.unsqueeze(0))[0].argmax()\n",
        "\n",
        "\n",
        "    def credibility(self, class_counts):\n",
        "        \"\"\"compute credibility of samples given their class_counts\"\"\"\n",
        "        alpha = self.k * len(self.layers) - np.max(class_counts, 1)\n",
        "        cred = np.zeros_like(alpha)\n",
        "        for i, a in enumerate(alpha):\n",
        "            cred[i] = np.sum(self.A >= a)\n",
        "        return cred / self.A.shape[0]\n",
        "\n",
        "    def find_nn_diff_class(self, x, label):\n",
        "        \"\"\"Find the nearest neighbor of x that has a different class from the\n",
        "        given label.\n",
        "        Parameters\n",
        "        ----------\n",
        "        x : torch.tensor\n",
        "            tensor of query samples, shape is (num_samples, ) + input_shape\n",
        "        label : torch.tensor\n",
        "            tensor of the labels, shape is (num_samples, )\n",
        "        Returns\n",
        "        -------\n",
        "        nn : np.array\n",
        "            array of indices of the nearest neighbor of each sample in x that\n",
        "            has a different label from the one specified\n",
        "        \"\"\"\n",
        "        nn = np.zeros(x.size(0))\n",
        "        for i in range(x.size(0)):\n",
        "            found_diff_class = False\n",
        "            k = 1e2\n",
        "            # find k nearest neighbors at a time, keep increasing k until at\n",
        "            # least one sample of a different class is found\n",
        "            while not found_diff_class:\n",
        "                _, I = self.get_neighbors(x[i].unsqueeze(0), k=int(k))[0]\n",
        "                I = I[0]\n",
        "                ind = np.where(label[i] != self.y_train[I])[0]\n",
        "                if len(ind) != 0:\n",
        "                    nn[i] = I[ind[0]]\n",
        "                    found_diff_class = True\n",
        "                else:\n",
        "                    k *= 10\n",
        "\n",
        "        return nn"
      ],
      "metadata": {
        "id": "Uh7mJzjbAP27"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**DKNN Attck**"
      ],
      "metadata": {
        "id": "CiyVsH9sJmxc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "INFTY = 1e20\n",
        "\n",
        "\n",
        "class DKNNAttackV2(object):\n",
        "    \"\"\"\n",
        "    Implement gradient-based attack on k-Nearest Neigbhor and its neural\n",
        "    network based variants.\n",
        "    Reference:\n",
        "    Minimum-Norm Adversarial Examples on KNN and KNN-Based Models\n",
        "    (Chawin Sitawarin, David Wagner)\n",
        "    https://arxiv.org/abs/2003.06559\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, dknn):\n",
        "        self.dknn = dknn\n",
        "        self.device = dknn.device\n",
        "        self.layers = dknn.layers\n",
        "        self.guide_reps = {}\n",
        "        self.thres = None\n",
        "        self.coeff = None\n",
        "\n",
        "        # classify x_train in dknn (leave-one-out)\n",
        "        out = self.dknn.classify(dknn.x_train, k=(dknn.k + 1))\n",
        "        eye = np.eye(dknn.num_classes)\n",
        "        labels = eye[dknn.y_train]\n",
        "        self.y_pred = (out - labels).argmax(1)\n",
        "\n",
        "    def __call__(self, x_orig, label, norm, guide_layer=['relu1'], m=100,\n",
        "                 init_mode=1, init_mode_k=1, binary_search_steps=5,\n",
        "                 max_iterations=500, learning_rate=1e-2, initial_const=1,\n",
        "                 max_linf=None, random_start=False, thres_steps=100,\n",
        "                 check_adv_steps=100, verbose=True):\n",
        "        \"\"\"\n",
        "        Parameters\n",
        "        ----------\n",
        "        dknn : DKNN object\n",
        "            DkNN (defined in lib/dknn.py) that we want to attack.\n",
        "        x_orig : torch.tensor\n",
        "            tensor of the original samples to attack. Does not need to require\n",
        "            gradients, shape is (num_samples, ) + input_shape.\n",
        "        label : torch.tensor\n",
        "            tensor of the label corresponding to x_orig.\n",
        "        norm : (2 or np.inf)\n",
        "            norm of adversarial perturbation.\n",
        "        guide_layer : str, optional\n",
        "            layer name in which we want to find guide samples. Default is\n",
        "            'relu1'.\n",
        "        m : int, optional\n",
        "            number of guide samples. Default is 100\n",
        "        init_mode : (1 or 2), optional\n",
        "            1 : initialize attack at <x_orig>.\n",
        "            2 : initialize attack at k-th neighbor of <x_orig> that is\n",
        "                not classified as <label>. k is specified by <init_mode_k>.\n",
        "            Default is 1.\n",
        "        init_mode_k : int, optional\n",
        "            specify k when init_mode is set to 2. Default is 1.\n",
        "        binary_search_step : int, optional\n",
        "            number of steps for binary search on the norm penalty constant.\n",
        "            Default is 5.\n",
        "        max_iterations : int, optional\n",
        "            number of optimization steps (per one binary search). Default is\n",
        "            500.\n",
        "        learning_rate : float , optional\n",
        "            step size or learning rate for the optimizer. Default is 1e-2.\n",
        "        initial_const : float, optional\n",
        "            a number the norm penalty constant should be initialized to.\n",
        "            Default is 1.\n",
        "        max_linf : float, optional\n",
        "            use to bound the L-inf norm of the attacks (addition to L-2 norm\n",
        "            penalty). Set to None to not use this option. Default is None.\n",
        "        random_start : bool, optional\n",
        "            whether or not to initialize the perturbation with small isotropic\n",
        "            Gaussian noise. Default is False.\n",
        "        thres_steps : int, optional\n",
        "            specify number of optimization steps to dynamically recalculate\n",
        "            threshold and guide samples. Picking a small number makes the\n",
        "            attack slower but more accurate. Default is 100.\n",
        "        check_adv_steps : int, optional\n",
        "            specify number of optimization steps to check if the perturbed\n",
        "            samples are misclassified and save them if they also have the\n",
        "            smallest perturbation seen so far. Default is 100.\n",
        "        verbose : bool, optional\n",
        "            whether or not to print progress. Default is True.\n",
        "        Returns\n",
        "        -------\n",
        "        x_adv : torch.tensor\n",
        "            adversarial examples found. If adversarial examples for some inputs\n",
        "            are not found, return those inputs.\n",
        "        \"\"\"\n",
        "\n",
        "        # min_, max_ = x_orig.min(), x_orig.max()\n",
        "        min_ = torch.tensor(0., device=self.device)\n",
        "        max_ = torch.tensor(1., device=self.device)\n",
        "        if max_linf is not None:\n",
        "            min_ = torch.max(x_orig - max_linf, min_)\n",
        "            max_ = torch.min(x_orig + max_linf, max_)\n",
        "        batch_size = x_orig.size(0)\n",
        "        x_adv = x_orig.clone()\n",
        "        label = label.cpu().numpy()\n",
        "        input_shape = x_orig.detach().cpu().numpy().shape\n",
        "        # initialize coeff for guide samples\n",
        "        self.coeff = torch.zeros((x_orig.size(0), m), device=self.device)\n",
        "        self.coeff[:, :m // 2] -= 1\n",
        "        self.coeff[:, m // 2:] += 1\n",
        "\n",
        "        def to_attack_space(x):\n",
        "            # map from [min_, max_] to [-1, +1]\n",
        "            a = (min_ + max_) / 2\n",
        "            b = (max_ - min_) / 2\n",
        "            x = (x - a) / b\n",
        "            # from [-1, +1] to approx. (-1, +1)\n",
        "            x = x * 0.999999\n",
        "            # from (-1, +1) to (-inf, +inf)\n",
        "            return self.atanh(x)\n",
        "\n",
        "        def to_model_space(x):\n",
        "            \"\"\"Transforms an input from the attack space to the model space.\n",
        "            This transformation and the returned gradient are elementwise.\"\"\"\n",
        "            # from (-inf, +inf) to (-1, +1)\n",
        "            x = torch.tanh(x)\n",
        "            # map from (-1, +1) to (min_, max_)\n",
        "            a = (min_ + max_) / 2\n",
        "            b = (max_ - min_) / 2\n",
        "            x = x * b + a\n",
        "            return x\n",
        "\n",
        "        # variables representing inputs in attack space will be prefixed with z\n",
        "        z_orig = to_attack_space(x_orig)\n",
        "        x_recon = to_model_space(z_orig)\n",
        "\n",
        "        # declare tensors that keep track of constants and binary search\n",
        "        const = torch.zeros((batch_size, ), device=self.device)\n",
        "        const += initial_const\n",
        "        lower_bound = torch.zeros_like(const)\n",
        "        upper_bound = torch.zeros_like(const) + INFTY\n",
        "        best_dist = torch.zeros_like(const) + INFTY\n",
        "\n",
        "        if init_mode == 1:\n",
        "            if verbose:\n",
        "                print('Using init_mode 1: initialize at original input <x_orig>.')\n",
        "        elif init_mode == 2:\n",
        "            if verbose:\n",
        "                print('Using init_mode 2: initialize at k-th neighbor of ' +\n",
        "                      'input <x_orig> that is not classified as <label>.')\n",
        "            with torch.no_grad():\n",
        "                # search for nearest neighbor of incorrect class\n",
        "                x_init = self.find_kth_neighbor_diff_class(\n",
        "                    x_orig, label, init_mode_k)\n",
        "                z_init = to_attack_space(x_init.to('cuda')) - z_orig\n",
        "\n",
        "        # make a list of number of guide samples that linearly decreases\n",
        "        start = (self.dknn.k + 1) // 2\n",
        "        end = max(m // 2, start + 1)\n",
        "        m_list = np.arange(start, end, (end - start) / binary_search_steps)\n",
        "\n",
        "        for binary_search_step in range(binary_search_steps):\n",
        "\n",
        "            # reduce number of guide samples for successful attacks\n",
        "            idx_m = binary_search_steps - binary_search_step - 1\n",
        "            m_new = np.ceil(m_list[idx_m]).astype(np.int32)\n",
        "\n",
        "            # initialize perturbation in transformed space\n",
        "            if not random_start:\n",
        "                z_delta = torch.zeros_like(z_orig, requires_grad=True)\n",
        "            else:\n",
        "                rand = np.random.randn(*input_shape) * 1e-2\n",
        "                z_delta = torch.tensor(\n",
        "                    rand, dtype=torch.float32, requires_grad=True,\n",
        "                    device=self.device)\n",
        "            with torch.no_grad():\n",
        "                if init_mode == 2:\n",
        "                    z_delta += z_init\n",
        "\n",
        "            # create a new optimizer\n",
        "            optimizer = optim.RMSprop([z_delta], lr=learning_rate)\n",
        "\n",
        "            for iteration in range(max_iterations):\n",
        "                optimizer.zero_grad()\n",
        "                x = to_model_space(z_orig + z_delta)\n",
        "\n",
        "                # adaptively choose threshold and guide samples every\n",
        "                # <thres_steps> iterations\n",
        "                with torch.no_grad():\n",
        "                    if iteration % thres_steps == 0:\n",
        "                        # thres = self.dknn.get_neighbors(x)[0][0][:, -1]\n",
        "                        # self.thres = torch.tensor(thres).to(self.device).view(\n",
        "                        #     batch_size, 1)\n",
        "                        self.thres = []\n",
        "                        thres = self.dknn.get_neighbors(x)\n",
        "                        for i in range(len(self.layers)):\n",
        "                            t = torch.tensor(thres[i][0][:, -1]).to(\n",
        "                                self.device).unsqueeze(-1)\n",
        "                            self.thres.append(t)\n",
        "                        self.find_guide_samples(\n",
        "                            x, label, m=m, layers=guide_layer)\n",
        "\n",
        "                reps = self.dknn.get_activations(x, requires_grad=True)\n",
        "                loss, dist = self.loss_function(x, reps, const, x_recon, norm)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                if (verbose and iteration %\n",
        "                        (np.ceil(max_iterations / 10)) == 0):\n",
        "                    print('    step: %d; loss: %.3f; dist: %.3f' %\n",
        "                          (iteration, loss.cpu().detach().numpy(),\n",
        "                           dist.mean().cpu().detach().numpy()))\n",
        "\n",
        "                # every <check_adv_steps>, save adversarial samples\n",
        "                # with minimal perturbation\n",
        "                if ((iteration + 1) % check_adv_steps == 0 or\n",
        "                        iteration == max_iterations):\n",
        "                    is_adv = self.check_adv(x, label)\n",
        "                    for i in range(batch_size):\n",
        "                        if is_adv[i] and best_dist[i] > dist[i]:\n",
        "                            x_adv[i] = x[i]\n",
        "                            best_dist[i] = dist[i]\n",
        "\n",
        "            # check how many attacks have succeeded\n",
        "            with torch.no_grad():\n",
        "                is_adv = self.check_adv(x, label)\n",
        "                if verbose:\n",
        "                    print('binary step: %d; num successful adv: %d/%d' %\n",
        "                          (binary_search_step, is_adv.sum(), batch_size))\n",
        "\n",
        "            for i in range(batch_size):\n",
        "                # set new upper and lower bounds\n",
        "                if is_adv[i]:\n",
        "                    upper_bound[i] = const[i]\n",
        "                    self.coeff[i, m_new:m // 2] = 0\n",
        "                    self.coeff[i, m // 2 + m_new:] = 0\n",
        "                else:\n",
        "                    lower_bound[i] = const[i]\n",
        "                # set new const\n",
        "                if upper_bound[i] == INFTY:\n",
        "                    # exponential search if adv has not been found\n",
        "                    const[i] *= 10\n",
        "                elif lower_bound[i] == 0:\n",
        "                    const[i] /= 10\n",
        "                else:\n",
        "                    # binary search if adv has been found\n",
        "                    const[i] = (lower_bound[i] + upper_bound[i]) / 2\n",
        "                # only keep adv with smallest l2dist\n",
        "                if is_adv[i] and best_dist[i] > dist[i]:\n",
        "                    x_adv[i] = x[i]\n",
        "                    best_dist[i] = dist[i]\n",
        "\n",
        "            # check the current attack success rate (combined with previous\n",
        "            # binary search steps)\n",
        "            if verbose:\n",
        "                with torch.no_grad():\n",
        "                    is_adv = self.check_adv(x_adv, label)\n",
        "                    print('binary step: %d; num successful adv so far: %d/%d' %\n",
        "                          (binary_search_step, is_adv.sum(), batch_size))\n",
        "\n",
        "        return x_adv\n",
        "\n",
        "    def check_adv(self, x, label):\n",
        "        \"\"\"Check if label of <x> predicted by <dknn> matches with <label>\"\"\"\n",
        "        y_pred = self.dknn.classify(x).argmax(1)\n",
        "        # y_pred = self.dknn.classify_soft(x).argmax(1)\n",
        "        return torch.tensor((y_pred != label).astype(np.float32)).to(self.device)\n",
        "        # class_counts = self.dknn.classify(x)\n",
        "        # y_pred = class_counts.argmax(1)\n",
        "        # eye = np.eye(len(class_counts[0]))\n",
        "        # pred_oh = eye[y_pred]\n",
        "        # max_counts = (pred_oh * class_counts).sum(1)\n",
        "        # return (max_counts >= 295) & (y_pred != label)\n",
        "\n",
        "    def loss_function(self, x, reps, const, x_recon, norm):\n",
        "        \"\"\"Returns the loss averaged over the batch (first dimension of x) and\n",
        "        norm squared of the perturbation\n",
        "        \"\"\"\n",
        "\n",
        "        batch_size = x.size(0)\n",
        "        # in case you want to compute the loss on all layers, use code below\n",
        "        adv_loss = torch.zeros(\n",
        "            (batch_size, len(self.layers)), device=self.device)\n",
        "        # find squared L-2 distance between original samples and their\n",
        "        # adversarial examples at each layer\n",
        "        for l, layer in enumerate(self.layers):\n",
        "            rep = reps[layer].view(batch_size, 1, -1)\n",
        "            dist = ((rep - self.guide_reps[layer]) ** 2).sum(2)\n",
        "            fx = dist - self.thres[l]\n",
        "            adv_loss[:, l] = F.relu(\n",
        "                self.coeff.to(self.device) * fx + 1e-5).sum(1)\n",
        "        adv_loss = adv_loss.sum(1)\n",
        "\n",
        "        # find L-2 norm squared of perturbation\n",
        "        if norm == 2:\n",
        "            dist = ((x - x_recon).view(batch_size, -1) ** 2).sum(1)\n",
        "            # total_loss is sum of perturbation norm and squared distance\n",
        "            # of representations, multiplied by constant\n",
        "            total_loss = dist + const * adv_loss\n",
        "            return total_loss.mean(), dist.sqrt()\n",
        "        elif norm == np.inf:\n",
        "            # (1) penalize l-inf directly\n",
        "            dist = (x - x_recon).view(batch_size, -1).abs().max(1)[0]\n",
        "            total_loss = dist + const * adv_loss\n",
        "            return total_loss.mean(), dist\n",
        "        else:\n",
        "            raise ValueError('Norm not implemented (only l2 and l-inf)')\n",
        "\n",
        "    def find_guide_samples(self, x, label, m=100, layers=['relu1']):\n",
        "        \"\"\"Find k nearest neighbors to <x> that all have the same class but not\n",
        "        equal to <label>\n",
        "        \"\"\"\n",
        "        num_classes = self.dknn.num_classes\n",
        "        x_train = self.dknn.x_train\n",
        "        y_train = self.dknn.y_train\n",
        "        batch_size = x.size(0)\n",
        "        nn = torch.zeros((m, ) + x.size())\n",
        "        nb = self.dknn.get_neighbors(x, k=x_train.size(0), layers=layers)\n",
        "\n",
        "        # find guide samples from the first layer\n",
        "        D, I = nb[0]\n",
        "        for i, (d, ind) in enumerate(zip(D, I)):\n",
        "            mean_dist = np.zeros((num_classes, ))\n",
        "            for j in range(num_classes):\n",
        "                mean_dist[j] = np.mean(\n",
        "                    d[np.where(y_train[ind] == j)[0]][:m // 2])\n",
        "            mean_dist[label[i]] += INFTY\n",
        "            nearest_label = mean_dist.argmin()\n",
        "            nn_ind = np.where(y_train[ind] == nearest_label)[0][:m // 2]\n",
        "            nn[m // 2:, i] = x_train[ind[nn_ind]]\n",
        "            nn_ind = np.where(y_train[ind] == label[i])[0][:m // 2]\n",
        "            nn[:m // 2, i] = x_train[ind[nn_ind]]\n",
        "\n",
        "        # initialize self.guide_reps if empty\n",
        "        if not self.guide_reps:\n",
        "            guide_rep = self.dknn.get_activations(\n",
        "                nn[:, 0], requires_grad=False)\n",
        "            for layer in layers:\n",
        "                # set a zero tensor before filling it\n",
        "                size = (batch_size, ) + guide_rep[layer].size()\n",
        "                self.guide_reps[layer] = torch.zeros(size, device=self.device)\n",
        "\n",
        "        # fill self.guide_reps\n",
        "        for i in range(batch_size):\n",
        "            guide_rep = self.dknn.get_activations(\n",
        "                nn[:, i], requires_grad=False)\n",
        "            for layer in layers:\n",
        "                self.guide_reps[layer][i] = guide_rep[layer].detach()\n",
        "\n",
        "    def find_kth_neighbor_diff_class(self, x, label, k):\n",
        "\n",
        "        nn = torch.zeros((x.size(0), ), dtype=torch.long)\n",
        "\n",
        "        for i in range(x.size(0)):\n",
        "            dist = ((x[i].cpu() - self.dknn.x_train).view(\n",
        "                self.dknn.x_train.size(0), -1) ** 2).sum(1)\n",
        "            # we want to exclude samples that are classified to the\n",
        "            # same label as x_orig\n",
        "            ind = np.where(self.y_pred == label[i])[0]\n",
        "            dist[ind] += INFTY\n",
        "            topk = torch.topk(dist, k, largest=False)[1]\n",
        "            nn[i] = dist[topk[-1]]\n",
        "\n",
        "        return self.dknn.x_train[nn]\n",
        "\n",
        "    @staticmethod\n",
        "    def atanh(x):\n",
        "        return 0.5 * torch.log((1 + x) / (1 - x))\n",
        "\n",
        "    @staticmethod\n",
        "    def sigmoid(x, a=1):\n",
        "        return 1 / (1 + torch.exp(-a * x))"
      ],
      "metadata": {
        "id": "hffdJXyQJgVK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Utils**"
      ],
      "metadata": {
        "id": "RFQpoh56JyVy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "\n",
        "def compute_lid(x, x_train, k, exclude_self=False):\n",
        "    \"\"\"\n",
        "    Calculate LID using the estimation from [1]\n",
        "    [1] Ma et al., \"Characterizing Adversarial Subspaces Using\n",
        "        Local Intrinsic Dimensionality,\" ICLR 2018.\n",
        "    \"\"\"\n",
        "\n",
        "    with torch.no_grad():\n",
        "        x = x.view((x.size(0), -1))\n",
        "        x_train = x_train.view((x_train.size(0), -1))\n",
        "        lid = torch.zeros((x.size(0), ))\n",
        "\n",
        "        for i, x_cur in enumerate(x):\n",
        "            dist = (x_cur.view(1, -1) - x_train).norm(2, 1)\n",
        "            # `largest` should be True when using cosine distance\n",
        "            if exclude_self:\n",
        "                topk_dist = dist.topk(k + 1, largest=False)[0][1:]\n",
        "            else:\n",
        "                topk_dist = dist.topk(k, largest=False)[0]\n",
        "            mean_log = torch.log(topk_dist / topk_dist[-1]).mean()\n",
        "            lid[i] = -1 / mean_log\n",
        "        return lid\n",
        "\n",
        "\n",
        "# def cal_class_lid(x, x_train, k, exclude_self=False):\n",
        "#     \"\"\"\n",
        "#     Calculate LID on sample using the estimation from [1]\n",
        "\n",
        "#     [1] Ma et al., \"Characterizing Adversarial Subspaces Using\n",
        "#         Local Intrinsic Dimensionality,\" ICLR 2018.\n",
        "#     \"\"\"\n",
        "\n",
        "#     x = x.view((x.size(0), -1))\n",
        "#     x_train = x_train.view((x_train.size(0), -1))\n",
        "#     lid = torch.zeros((x.size(0), ))\n",
        "\n",
        "#     for i, x_cur in enumerate(x):\n",
        "#         dist = (x_cur.view(1, -1) - x_train).norm(2, 1)\n",
        "#         # `largest` should be True when using cosine distance\n",
        "#         if exclude_self:\n",
        "#             topk_dist = dist.topk(k + 1, largest=False)[0][1:]\n",
        "#         else:\n",
        "#             topk_dist = dist.topk(k, largest=False)[0]\n",
        "#         mean_log = torch.log(topk_dist / topk_dist[-1]).mean()\n",
        "#         lid[i] = -1 / mean_log\n",
        "#     return lid\n",
        "\n",
        "\n",
        "def compute_spnorm(inputs, dknn, layers, batch_size=200):\n",
        "\n",
        "    assert inputs.requires_grad\n",
        "\n",
        "    num_total = inputs.size(0)\n",
        "    norm = np.zeros((num_total, len(layers)))\n",
        "    num_batches = int(np.ceil(num_total / batch_size))\n",
        "\n",
        "    for i in range(num_batches):\n",
        "        begin, end = i * batch_size, (i + 1) * batch_size\n",
        "        x = inputs[begin:end]\n",
        "        reps = dknn.get_activations(x)\n",
        "        for l, layer in enumerate(layers):\n",
        "            y = reps[layer]\n",
        "            norm[begin:end, l] = compute_spnorm_batch(x, y)\n",
        "\n",
        "    return norm\n",
        "\n",
        "\n",
        "def compute_spnorm_batch(inputs, output):\n",
        "    \"\"\"\n",
        "    :param inputs: (batch_size, input_size)\n",
        "    :param output: (batch_size, output_size)\n",
        "    :return: jacobian: (batch_size, output_size, input_size)\n",
        "    \"\"\"\n",
        "\n",
        "    batch_size, input_dim = inputs.view(inputs.size(0), -1).size()\n",
        "    output = output.view(batch_size, -1)\n",
        "    jacobian = torch.zeros((batch_size, output.size(1), input_dim))\n",
        "    for i in range(output.size(1)):\n",
        "        grad = torch.autograd.grad(\n",
        "            output[:, i].sum(), inputs, retain_graph=True)[0]\n",
        "        jacobian[:, i, :] = grad.view(batch_size, input_dim)\n",
        "\n",
        "    norm = np.zeros((batch_size, ))\n",
        "    for i in range(batch_size):\n",
        "        norm[i] = np.linalg.norm(jacobian[i].detach().cpu().numpy(), 2)\n",
        "\n",
        "    return norm"
      ],
      "metadata": {
        "id": "7ZxhPwFbJ2JV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **adv_model**\n"
      ],
      "metadata": {
        "id": "kSDRIGDUwMce"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class PGDModel(nn.Module):\n",
        "    \"\"\"\n",
        "    code adapted from\n",
        "    https://github.com/karandwivedi42/adversarial/blob/master/main.py\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, basic_net, config):\n",
        "        super(PGDModel, self).__init__()\n",
        "        self.basic_net = basic_net\n",
        "        self.rand = config['random_start']\n",
        "        self.step_size = config['step_size']\n",
        "        self.epsilon = config['epsilon']\n",
        "        self.num_steps = config['num_steps']\n",
        "        assert config['loss_func'] == 'xent', 'Only xent supported for now.'\n",
        "\n",
        "    def forward(self, inputs, targets, attack=False):\n",
        "        if not attack:\n",
        "            return self.basic_net(inputs)\n",
        "\n",
        "        x = inputs.clone()\n",
        "        if self.rand:\n",
        "            x = x + torch.zeros_like(x).uniform_(-self.epsilon, self.epsilon)\n",
        "        for _ in range(self.num_steps):\n",
        "            x.requires_grad_()\n",
        "            with torch.enable_grad():\n",
        "                logits = self.basic_net(x)\n",
        "                loss = F.cross_entropy(logits, targets, reduction='sum')\n",
        "            grad = torch.autograd.grad(loss, x)[0]\n",
        "            x = x.detach() + self.step_size * torch.sign(grad.detach())\n",
        "            x = torch.min(torch.max(x, inputs.detach() - self.epsilon),\n",
        "                          inputs.detach() + self.epsilon)\n",
        "            x = torch.clamp(x, 0, 1)\n",
        "\n",
        "        return self.basic_net(x)\n",
        "\n",
        "\n",
        "class PGDL2Model(nn.Module):\n",
        "    def __init__(self, basic_net, config):\n",
        "        super(PGDL2Model, self).__init__()\n",
        "        self.basic_net = basic_net\n",
        "        self.epsilon = config['epsilon']\n",
        "        self.rand = config['random_start']\n",
        "        self.step_size = config['step_size']\n",
        "        self.num_steps = config['num_steps']\n",
        "        assert config['loss_func'] == 'xent', 'Only xent supported for now.'\n",
        "\n",
        "    def forward(self, inputs, targets, attack=False):\n",
        "        if not attack:\n",
        "            return self.basic_net(inputs)\n",
        "\n",
        "        x = inputs.clone()\n",
        "        if self.rand:\n",
        "            x = x + torch.zeros_like(x).normal_(0, self.step_size)\n",
        "\n",
        "        for _ in range(self.num_steps):\n",
        "            x.requires_grad_()\n",
        "            with torch.enable_grad():\n",
        "                logits = self.basic_net(x)\n",
        "                loss = F.cross_entropy(logits, targets, reduction='sum')\n",
        "            grad = torch.autograd.grad(loss, x)[0].detach()\n",
        "            grad_norm = grad.view(x.size(0), -1).norm(2, 1)\n",
        "            delta = self.step_size * grad / grad_norm.view(x.size(0), 1, 1, 1)\n",
        "            x = x.detach() + delta\n",
        "            diff = (x - inputs).view(x.size(0), -1).renorm(2, 0, self.epsilon)\n",
        "            x = diff.view(x.size()) + inputs\n",
        "            x.clamp_(0, 1)\n",
        "\n",
        "        return self.basic_net(x)"
      ],
      "metadata": {
        "id": "QVzLe5-rwM6I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **DKNN attack_v2**"
      ],
      "metadata": {
        "id": "VqBtVIBODEmm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''Implement gradient-based attack on DkNN and kNN (version 2)'''\n",
        "\n",
        "\n",
        "INFTY = 1e20\n",
        "\n",
        "\n",
        "class DKNNAttackV2(object):\n",
        "   \n",
        "    def __init__(self, dknn):\n",
        "        self.dknn = dknn\n",
        "        self.device = dknn.device\n",
        "        self.layers = dknn.layers\n",
        "        self.guide_reps = {}\n",
        "        self.thres = None\n",
        "        self.coeff = None\n",
        "\n",
        "        # classify x_train in dknn (leave-one-out)\n",
        "        out = self.dknn.classify(dknn.x_train, k=(dknn.k + 1))\n",
        "        eye = np.eye(dknn.num_classes)\n",
        "        labels = eye[dknn.y_train]\n",
        "        self.y_pred = (out - labels).argmax(1)\n",
        "\n",
        "    def __call__(self, x_orig, label, norm, guide_layer=['relu1'], m=100,\n",
        "                 init_mode=1, init_mode_k=1, binary_search_steps=5,\n",
        "                 max_iterations=500, learning_rate=1e-2, initial_const=1,\n",
        "                 max_linf=None, random_start=False, thres_steps=100,\n",
        "                 check_adv_steps=100, verbose=True):\n",
        "        \"\"\"\n",
        "        Parameters\n",
        "        ----------\n",
        "        dknn : DKNN object\n",
        "            DkNN (defined in lib/dknn.py) that we want to attack.\n",
        "        x_orig : torch.tensor\n",
        "            tensor of the original samples to attack. Does not need to require\n",
        "            gradients, shape is (num_samples, ) + input_shape.\n",
        "        label : torch.tensor\n",
        "            tensor of the label corresponding to x_orig.\n",
        "        norm : (2 or np.inf)\n",
        "            norm of adversarial perturbation.\n",
        "        guide_layer : str, optional\n",
        "            layer name in which we want to find guide samples. Default is\n",
        "            'relu1'.\n",
        "        m : int, optional\n",
        "            number of guide samples. Default is 100\n",
        "        init_mode : (1 or 2), optional\n",
        "            1 : initialize attack at <x_orig>.\n",
        "            2 : initialize attack at k-th neighbor of <x_orig> that is\n",
        "                not classified as <label>. k is specified by <init_mode_k>.\n",
        "            Default is 1.\n",
        "        init_mode_k : int, optional\n",
        "            specify k when init_mode is set to 2. Default is 1.\n",
        "        binary_search_step : int, optional\n",
        "            number of steps for binary search on the norm penalty constant.\n",
        "            Default is 5.\n",
        "        max_iterations : int, optional\n",
        "            number of optimization steps (per one binary search). Default is\n",
        "            500.\n",
        "        learning_rate : float , optional\n",
        "            step size or learning rate for the optimizer. Default is 1e-2.\n",
        "        initial_const : float, optional\n",
        "            a number the norm penalty constant should be initialized to.\n",
        "            Default is 1.\n",
        "        max_linf : float, optional\n",
        "            use to bound the L-inf norm of the attacks (addition to L-2 norm\n",
        "            penalty). Set to None to not use this option. Default is None.\n",
        "        random_start : bool, optional\n",
        "            whether or not to initialize the perturbation with small isotropic\n",
        "            Gaussian noise. Default is False.\n",
        "        thres_steps : int, optional\n",
        "            specify number of optimization steps to dynamically recalculate\n",
        "            threshold and guide samples. Picking a small number makes the\n",
        "            attack slower but more accurate. Default is 100.\n",
        "        check_adv_steps : int, optional\n",
        "            specify number of optimization steps to check if the perturbed\n",
        "            samples are misclassified and save them if they also have the\n",
        "            smallest perturbation seen so far. Default is 100.\n",
        "        verbose : bool, optional\n",
        "            whether or not to print progress. Default is True.\n",
        "        Returns\n",
        "        -------\n",
        "        x_adv : torch.tensor\n",
        "            adversarial examples found. If adversarial examples for some inputs\n",
        "            are not found, return those inputs.\n",
        "        \"\"\"\n",
        "\n",
        "        # min_, max_ = x_orig.min(), x_orig.max()\n",
        "        min_ = torch.tensor(0., device=self.device)\n",
        "        max_ = torch.tensor(1., device=self.device)\n",
        "        if max_linf is not None:\n",
        "            min_ = torch.max(x_orig - max_linf, min_)\n",
        "            max_ = torch.min(x_orig + max_linf, max_)\n",
        "        batch_size = x_orig.size(0)\n",
        "        x_adv = x_orig.clone()\n",
        "        label = label.cpu().numpy()\n",
        "        input_shape = x_orig.detach().cpu().numpy().shape\n",
        "        # initialize coeff for guide samples\n",
        "        self.coeff = torch.zeros((x_orig.size(0), m), device=self.device)\n",
        "        self.coeff[:, :m // 2] -= 1\n",
        "        self.coeff[:, m // 2:] += 1\n",
        "\n",
        "        def to_attack_space(x):\n",
        "            # map from [min_, max_] to [-1, +1]\n",
        "            a = (min_ + max_) / 2\n",
        "            b = (max_ - min_) / 2\n",
        "            x = (x - a) / b\n",
        "            # from [-1, +1] to approx. (-1, +1)\n",
        "            x = x * 0.999999\n",
        "            # from (-1, +1) to (-inf, +inf)\n",
        "            return self.atanh(x)\n",
        "\n",
        "        def to_model_space(x):\n",
        "            \"\"\"Transforms an input from the attack space to the model space.\n",
        "            This transformation and the returned gradient are elementwise.\"\"\"\n",
        "            # from (-inf, +inf) to (-1, +1)\n",
        "            x = torch.tanh(x)\n",
        "            # map from (-1, +1) to (min_, max_)\n",
        "            a = (min_ + max_) / 2\n",
        "            b = (max_ - min_) / 2\n",
        "            x = x * b + a\n",
        "            return x\n",
        "\n",
        "        # variables representing inputs in attack space will be prefixed with z\n",
        "        z_orig = to_attack_space(x_orig)\n",
        "        x_recon = to_model_space(z_orig)\n",
        "\n",
        "        # declare tensors that keep track of constants and binary search\n",
        "        const = torch.zeros((batch_size, ), device=self.device)\n",
        "        const += initial_const\n",
        "        lower_bound = torch.zeros_like(const)\n",
        "        upper_bound = torch.zeros_like(const) + INFTY\n",
        "        best_dist = torch.zeros_like(const) + INFTY\n",
        "\n",
        "        if init_mode == 1:\n",
        "            if verbose:\n",
        "                print('Using init_mode 1: initialize at original input <x_orig>.')\n",
        "        elif init_mode == 2:\n",
        "            if verbose:\n",
        "                print('Using init_mode 2: initialize at k-th neighbor of ' +\n",
        "                      'input <x_orig> that is not classified as <label>.')\n",
        "            with torch.no_grad():\n",
        "                # search for nearest neighbor of incorrect class\n",
        "                x_init = self.find_kth_neighbor_diff_class(\n",
        "                    x_orig, label, init_mode_k)\n",
        "                z_init = to_attack_space(x_init.to('cuda')) - z_orig\n",
        "\n",
        "        # make a list of number of guide samples that linearly decreases\n",
        "        start = (self.dknn.k + 1) // 2\n",
        "        end = max(m // 2, start + 1)\n",
        "        m_list = np.arange(start, end, (end - start) / binary_search_steps)\n",
        "\n",
        "        for binary_search_step in range(binary_search_steps):\n",
        "\n",
        "            # reduce number of guide samples for successful attacks\n",
        "            idx_m = binary_search_steps - binary_search_step - 1\n",
        "            m_new = np.ceil(m_list[idx_m]).astype(np.int32)\n",
        "\n",
        "            # initialize perturbation in transformed space\n",
        "            if not random_start:\n",
        "                z_delta = torch.zeros_like(z_orig, requires_grad=True)\n",
        "            else:\n",
        "                rand = np.random.randn(*input_shape) * 1e-2\n",
        "                z_delta = torch.tensor(\n",
        "                    rand, dtype=torch.float32, requires_grad=True,\n",
        "                    device=self.device)\n",
        "            with torch.no_grad():\n",
        "                if init_mode == 2:\n",
        "                    z_delta += z_init\n",
        "\n",
        "            # create a new optimizer\n",
        "            optimizer = optim.RMSprop([z_delta], lr=learning_rate)\n",
        "\n",
        "            for iteration in range(max_iterations):\n",
        "                optimizer.zero_grad()\n",
        "                x = to_model_space(z_orig + z_delta)\n",
        "\n",
        "                # adaptively choose threshold and guide samples every\n",
        "                # <thres_steps> iterations\n",
        "                with torch.no_grad():\n",
        "                    if iteration % thres_steps == 0:\n",
        "                        # thres = self.dknn.get_neighbors(x)[0][0][:, -1]\n",
        "                        # self.thres = torch.tensor(thres).to(self.device).view(\n",
        "                        #     batch_size, 1)\n",
        "                        self.thres = []\n",
        "                        thres = self.dknn.get_neighbors(x)\n",
        "                        for i in range(len(self.layers)):\n",
        "                            t = torch.tensor(thres[i][0][:, -1]).to(\n",
        "                                self.device).unsqueeze(-1)\n",
        "                            self.thres.append(t)\n",
        "                        self.find_guide_samples(\n",
        "                            x, label, m=m, layers=guide_layer)\n",
        "\n",
        "                reps = self.dknn.get_activations(x, requires_grad=True)\n",
        "                loss, dist = self.loss_function(x, reps, const, x_recon, norm)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                if (verbose and iteration %\n",
        "                        (np.ceil(max_iterations / 10)) == 0):\n",
        "                    print('    step: %d; loss: %.3f; dist: %.3f' %\n",
        "                          (iteration, loss.cpu().detach().numpy(),\n",
        "                           dist.mean().cpu().detach().numpy()))\n",
        "\n",
        "                # every <check_adv_steps>, save adversarial samples\n",
        "                # with minimal perturbation\n",
        "                if ((iteration + 1) % check_adv_steps == 0 or\n",
        "                        iteration == max_iterations):\n",
        "                    is_adv = self.check_adv(x, label)\n",
        "                    for i in range(batch_size):\n",
        "                        if is_adv[i] and best_dist[i] > dist[i]:\n",
        "                            x_adv[i] = x[i]\n",
        "                            best_dist[i] = dist[i]\n",
        "\n",
        "            # check how many attacks have succeeded\n",
        "            with torch.no_grad():\n",
        "                is_adv = self.check_adv(x, label)\n",
        "                if verbose:\n",
        "                    print('binary step: %d; num successful adv: %d/%d' %\n",
        "                          (binary_search_step, is_adv.sum(), batch_size))\n",
        "\n",
        "            for i in range(batch_size):\n",
        "                # set new upper and lower bounds\n",
        "                if is_adv[i]:\n",
        "                    upper_bound[i] = const[i]\n",
        "                    self.coeff[i, m_new:m // 2] = 0\n",
        "                    self.coeff[i, m // 2 + m_new:] = 0\n",
        "                else:\n",
        "                    lower_bound[i] = const[i]\n",
        "                # set new const\n",
        "                if upper_bound[i] == INFTY:\n",
        "                    # exponential search if adv has not been found\n",
        "                    const[i] *= 10\n",
        "                elif lower_bound[i] == 0:\n",
        "                    const[i] /= 10\n",
        "                else:\n",
        "                    # binary search if adv has been found\n",
        "                    const[i] = (lower_bound[i] + upper_bound[i]) / 2\n",
        "                # only keep adv with smallest l2dist\n",
        "                if is_adv[i] and best_dist[i] > dist[i]:\n",
        "                    x_adv[i] = x[i]\n",
        "                    best_dist[i] = dist[i]\n",
        "\n",
        "            # check the current attack success rate (combined with previous\n",
        "            # binary search steps)\n",
        "            if verbose:\n",
        "                with torch.no_grad():\n",
        "                    is_adv = self.check_adv(x_adv, label)\n",
        "                    print('binary step: %d; num successful adv so far: %d/%d' %\n",
        "                          (binary_search_step, is_adv.sum(), batch_size))\n",
        "\n",
        "        return x_adv\n",
        "\n",
        "    def check_adv(self, x, label):\n",
        "        \"\"\"Check if label of <x> predicted by <dknn> matches with <label>\"\"\"\n",
        "        y_pred = self.dknn.classify(x).argmax(1)\n",
        "        # y_pred = self.dknn.classify_soft(x).argmax(1)\n",
        "        return torch.tensor((y_pred != label).astype(np.float32)).to(self.device)\n",
        "        # class_counts = self.dknn.classify(x)\n",
        "        # y_pred = class_counts.argmax(1)\n",
        "        # eye = np.eye(len(class_counts[0]))\n",
        "        # pred_oh = eye[y_pred]\n",
        "        # max_counts = (pred_oh * class_counts).sum(1)\n",
        "        # return (max_counts >= 295) & (y_pred != label)\n",
        "\n",
        "    def loss_function(self, x, reps, const, x_recon, norm):\n",
        "        \"\"\"Returns the loss averaged over the batch (first dimension of x) and\n",
        "        norm squared of the perturbation\n",
        "        \"\"\"\n",
        "\n",
        "        batch_size = x.size(0)\n",
        "        # in case you want to compute the loss on all layers, use code below\n",
        "        adv_loss = torch.zeros(\n",
        "            (batch_size, len(self.layers)), device=self.device)\n",
        "        # find squared L-2 distance between original samples and their\n",
        "        # adversarial examples at each layer\n",
        "        for l, layer in enumerate(self.layers):\n",
        "            rep = reps[layer].view(batch_size, 1, -1)\n",
        "            dist = ((rep - self.guide_reps[layer]) ** 2).sum(2)\n",
        "            fx = dist - self.thres[l]\n",
        "            adv_loss[:, l] = F.relu(\n",
        "                self.coeff.to(self.device) * fx + 1e-5).sum(1)\n",
        "        adv_loss = adv_loss.sum(1)\n",
        "\n",
        "        # find L-2 norm squared of perturbation\n",
        "        if norm == 2:\n",
        "            dist = ((x - x_recon).view(batch_size, -1) ** 2).sum(1)\n",
        "            # total_loss is sum of perturbation norm and squared distance\n",
        "            # of representations, multiplied by constant\n",
        "            total_loss = dist + const * adv_loss\n",
        "            return total_loss.mean(), dist.sqrt()\n",
        "        elif norm == np.inf:\n",
        "            # (1) penalize l-inf directly\n",
        "            dist = (x - x_recon).view(batch_size, -1).abs().max(1)[0]\n",
        "            total_loss = dist + const * adv_loss\n",
        "            return total_loss.mean(), dist\n",
        "        else:\n",
        "            raise ValueError('Norm not implemented (only l2 and l-inf)')\n",
        "\n",
        "    def find_guide_samples(self, x, label, m=100, layers=['relu1']):\n",
        "        \"\"\"Find k nearest neighbors to <x> that all have the same class but not\n",
        "        equal to <label>\n",
        "        \"\"\"\n",
        "        num_classes = self.dknn.num_classes\n",
        "        x_train = self.dknn.x_train\n",
        "        y_train = self.dknn.y_train\n",
        "        batch_size = x.size(0)\n",
        "        nn = torch.zeros((m, ) + x.size())\n",
        "        nb = self.dknn.get_neighbors(x, k=x_train.size(0), layers=layers)\n",
        "\n",
        "        # find guide samples from the first layer\n",
        "        D, I = nb[0]\n",
        "        for i, (d, ind) in enumerate(zip(D, I)):\n",
        "            mean_dist = np.zeros((num_classes, ))\n",
        "            for j in range(num_classes):\n",
        "                mean_dist[j] = np.mean(\n",
        "                    d[np.where(y_train[ind] == j)[0]][:m // 2])\n",
        "            mean_dist[label[i]] += INFTY\n",
        "            nearest_label = mean_dist.argmin()\n",
        "            nn_ind = np.where(y_train[ind] == nearest_label)[0][:m // 2]\n",
        "            nn[m // 2:, i] = x_train[ind[nn_ind]]\n",
        "            nn_ind = np.where(y_train[ind] == label[i])[0][:m // 2]\n",
        "            nn[:m // 2, i] = x_train[ind[nn_ind]]\n",
        "\n",
        "        # initialize self.guide_reps if empty\n",
        "        if not self.guide_reps:\n",
        "            guide_rep = self.dknn.get_activations(\n",
        "                nn[:, 0], requires_grad=False)\n",
        "            for layer in layers:\n",
        "                # set a zero tensor before filling it\n",
        "                size = (batch_size, ) + guide_rep[layer].size()\n",
        "                self.guide_reps[layer] = torch.zeros(size, device=self.device)\n",
        "\n",
        "        # fill self.guide_reps\n",
        "        for i in range(batch_size):\n",
        "            guide_rep = self.dknn.get_activations(\n",
        "                nn[:, i], requires_grad=False)\n",
        "            for layer in layers:\n",
        "                self.guide_reps[layer][i] = guide_rep[layer].detach()\n",
        "\n",
        "    def find_kth_neighbor_diff_class(self, x, label, k):\n",
        "\n",
        "        nn = torch.zeros((x.size(0), ), dtype=torch.long)\n",
        "\n",
        "        for i in range(x.size(0)):\n",
        "            dist = ((x[i].cpu() - self.dknn.x_train).view(\n",
        "                self.dknn.x_train.size(0), -1) ** 2).sum(1)\n",
        "            # we want to exclude samples that are classified to the\n",
        "            # same label as x_orig\n",
        "            ind = np.where(self.y_pred == label[i])[0]\n",
        "            dist[ind] += INFTY\n",
        "            topk = torch.topk(dist, k, largest=False)[1]\n",
        "            nn[i] = dist[topk[-1]]\n",
        "\n",
        "        return self.dknn.x_train[nn]\n",
        "\n",
        "    @staticmethod\n",
        "    def atanh(x):\n",
        "        return 0.5 * torch.log((1 + x) / (1 - x))\n",
        "\n",
        "    @staticmethod\n",
        "    def sigmoid(x, a=1):\n",
        "        return 1 / (1 + torch.exp(-a * x))"
      ],
      "metadata": {
        "id": "OrjlyLRaDOhf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Attack_demo**"
      ],
      "metadata": {
        "id": "tum_RTNywFhj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3PjKkclIvGnZ",
        "outputId": "7de36d0c-fbe6-4aa9-fbf0-280fcf44d43e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9671\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
        "\n",
        "# Set all random seeds\n",
        "seed = 2020\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "(x_train, y_train), (x_valid, y_valid), (x_test, y_test) = load_mnist_all(\n",
        "    '/data', val_size=0.1, shuffle=True, seed=seed)\n",
        "\n",
        "model_name = 'mnist_at.h5'\n",
        "basic_net = BasicModel()\n",
        "config = {'epsilon': 0.3,\n",
        "          'num_steps': 40,\n",
        "          'step_size': 0.01,\n",
        "          'random_start': True,\n",
        "          'loss_func': 'xent'}\n",
        "net = PGDL2Model(basic_net, config)\n",
        "\n",
        "# Set up model directory\n",
        "save_dir = os.path.join(os.getcwd(), 'saved_models/mnist/')\n",
        "if not os.path.isdir(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "model_path = os.path.join(save_dir, model_name)\n",
        "\n",
        "net = net.to(device)\n",
        "net.load_state_dict(torch.load(model_path))\n",
        "net = net.basic_net\n",
        "net.eval()\n",
        "\n",
        "layers = ['relu1', 'relu2', 'relu3', 'fc']\n",
        "\n",
        "dknn = DKNNL2(net, x_train, y_train, x_valid, y_valid, layers, \n",
        "              k=75, cosine=True, num_classes=10)\n",
        "\n",
        "layers = ['relu3']\n",
        "\n",
        "dknn = DKNNL2(net, x_train, y_train, x_valid, y_valid, layers, \n",
        "              k=15, cosine=False, num_classes=10)\n",
        "\n",
        "net_knn = KNNModel()\n",
        "layers = ['identity']\n",
        "dknn = DKNNL2(net_knn, x_train, y_train, x_test, y_test, \n",
        "              layers, k=5, num_classes=10)\n",
        "\n",
        "with torch.no_grad():\n",
        "    y_pred = dknn.classify(x_test)\n",
        "    ind = np.where(y_pred.argmax(1) == y_test.numpy())[0]\n",
        "    print((y_pred.argmax(1) == y_test.numpy()).sum() / y_test.size(0))\n",
        "\n",
        "\n",
        "def attack_batch(attack, x, y, init_mode, init_mode_k, batch_size):\n",
        "    x_adv = torch.zeros_like(x)\n",
        "    total_num = x.size(0)\n",
        "    num_batches = int(np.ceil(total_num / batch_size))\n",
        "    for i in range(num_batches):\n",
        "        begin = i * batch_size\n",
        "        end = (i + 1) * batch_size\n",
        "        x_adv[begin:end] = attack(\n",
        "            x[begin:end], y[begin:end], 2, guide_layer=layers, m=6,\n",
        "            init_mode=init_mode, init_mode_k=init_mode_k,\n",
        "            binary_search_steps=10, max_iterations=1000, learning_rate=1e-1,\n",
        "            initial_const=1e0, max_linf=None, random_start=True,\n",
        "            thres_steps=200, check_adv_steps=200, verbose=False)\n",
        "    return x_adv\n",
        "\n",
        "num = 2\n",
        "\n",
        "def full_eval(dknn):\n",
        "    with torch.no_grad():\n",
        "        y_pred = dknn.classify(x_test)\n",
        "        ind = np.where(y_pred.argmax(1) == y_test.numpy())[0]\n",
        "    print((y_pred.argmax(1) == y_test.numpy()).sum() / y_test.size(0))\n",
        "    \n",
        "    dist_all = np.zeros(num) + 1e9\n",
        "    x_adv_all = x_test[ind][:num].clone()\n",
        "    attack = DKNNAttackV2(dknn)\n",
        "    \n",
        "    x_adv = attack_batch(\n",
        "        attack, x_test[ind][:num].cuda(), y_test[ind][:num], 1, 1, 100)\n",
        "    with torch.no_grad():\n",
        "        y_pred = dknn.classify(x_adv)\n",
        "        ind_adv = y_pred.argmax(1) != y_test[ind][:num].numpy()\n",
        "        dist = (x_adv.cpu() - x_test[ind][:num]).view(\n",
        "            num, -1).norm(2, 1).numpy()\n",
        "    for i in range(num):\n",
        "        if ind_adv[i] and (dist[i] < dist_all[i]):\n",
        "            dist_all[i] = dist[i]\n",
        "            x_adv_all[i] = x_adv[i]\n",
        "            \n",
        "    for k in range(1, 3):\n",
        "        x_adv = attack_batch(\n",
        "            attack, x_test[ind][:num].cuda(), y_test[ind][:num], 2, k, 100)\n",
        "        with torch.no_grad():\n",
        "            y_pred = dknn.classify(x_adv)\n",
        "            ind_adv = y_pred.argmax(1) != y_test[ind][:num].numpy()\n",
        "            dist = (x_adv.cpu() - x_test[ind][:num]).view(\n",
        "                num, -1).norm(2, 1).numpy()\n",
        "        for i in range(num):\n",
        "            if ind_adv[i] and (dist[i] < dist_all[i]):\n",
        "                dist_all[i] = dist[i]\n",
        "                x_adv_all[i] = x_adv[i]\n",
        "                \n",
        "    adv_acc = (dist_all == 1e9).mean()\n",
        "    print('adv accuracy: %.4f, mean dist: %.4f' % (\n",
        "        adv_acc, dist_all[dist_all < 1e9].mean()))\n",
        "    return dist_all, x_adv_all\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start = time.time()\n",
        "dist, x_adv = full_eval(dknn)\n",
        "print('Total time %.4fs' % (time.time() - start))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "teL1rDPc_B1j",
        "outputId": "e81474c5-6f31-463e-afce-436eddacfbc1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9671\n",
            "adv accuracy: 0.0000, mean dist: 2.6679\n",
            "Total time 175.0470s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dist.mean()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ii7L9Al-7iL",
        "outputId": "7791a3a4-906e-4107-cbc3-caa3171ae101"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.6678977012634277"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "i = 0\n",
        "print('clean')\n",
        "plt.imshow(x_test[i].detach().reshape(28, 28), cmap='gray')\n",
        "plt.show()\n",
        "print('adv')\n",
        "plt.imshow(x_adv[i].detach().reshape(28, 28), cmap='gray')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 548
        },
        "id": "pC3T-Jlm-_DY",
        "outputId": "bb241c48-65ca-4405-bbfd-b1c770c4b0be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "clean\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAM3ElEQVR4nO3dXahc9bnH8d/vpCmI6UXiS9ik0bTBC8tBEo1BSCxbQktOvIjFIM1FyYHi7kWUFkuo2It4WaQv1JvALkrTkmMJpGoQscmJxVDU4o5Es2NIjCGaxLxYIjQRJMY+vdjLso0za8ZZa2ZN8nw/sJmZ9cya9bDMz7VmvczfESEAV77/aroBAINB2IEkCDuQBGEHkiDsQBJfGeTCbHPoH+iziHCr6ZW27LZX2j5o+7Dth6t8FoD+cq/n2W3PkHRI0nckHZf0mqS1EfFWyTxs2YE+68eWfamkwxFxJCIuSPqTpNUVPg9AH1UJ+zxJx6a9Pl5M+xzbY7YnbE9UWBaAivp+gC4ixiWNS+zGA02qsmU/IWn+tNdfL6YBGEJVwv6apJtsf8P2VyV9X9L2etoCULeed+Mj4qLtByT9RdIMSU9GxP7aOgNQq55PvfW0ML6zA33Xl4tqAFw+CDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJ9Dw+uyTZPirpnKRPJV2MiCV1NAWgfpXCXrgrIv5Rw+cA6CN244EkqoY9JO2wvcf2WKs32B6zPWF7ouKyAFTgiOh9ZnteRJywfb2knZIejIjdJe/vfWEAuhIRbjW90pY9Ik4Uj2ckPS1paZXPA9A/PYfd9tW2v/bZc0nflTRZV2MA6lXlaPxcSU/b/uxz/i8iXqilKwC1q/Sd/UsvjO/sQN/15Ts7gMsHYQeSIOxAEoQdSIKwA0nUcSNMCmvWrGlbu//++0vnff/990vrH3/8cWl9y5YtpfVTp061rR0+fLh0XuTBlh1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkuCuty4dOXKkbW3BggWDa6SFc+fOta3t379/gJ0Ml+PHj7etPfbYY6XzTkxcvr+ixl1vQHKEHUiCsANJEHYgCcIOJEHYgSQIO5AE97N3qeye9VtuuaV03gMHDpTWb7755tL6rbfeWlofHR1tW7vjjjtK5z127Fhpff78+aX1Ki5evFha/+CDD0rrIyMjPS/7vffeK61fzufZ22HLDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJcD/7FWD27Nlta4sWLSqdd8+ePaX122+/vaeeutHp9/IPHTpUWu90/cKcOXPa1tavX18676ZNm0rrw6zn+9ltP2n7jO3JadPm2N5p++3isf2/NgBDoZvd+N9LWnnJtIcl7YqImyTtKl4DGGIdwx4RuyWdvWTyakmbi+ebJd1Tc18AatbrtfFzI+Jk8fyUpLnt3mh7TNJYj8sBUJPKN8JERJQdeIuIcUnjEgfogCb1eurttO0RSSoez9TXEoB+6DXs2yWtK56vk/RsPe0A6JeO59ltPyVpVNK1kk5L2ijpGUlbJd0g6V1J90XEpQfxWn0Wu/Ho2r333lta37p1a2l9cnKybe2uu+4qnffs2Y7/nIdWu/PsHb+zR8TaNqUVlToCMFBcLgskQdiBJAg7kARhB5Ig7EAS3OKKxlx//fWl9X379lWaf82aNW1r27ZtK533csaQzUByhB1IgrADSRB2IAnCDiRB2IEkCDuQBEM2ozGdfs75uuuuK61/+OGHpfWDBw9+6Z6uZGzZgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJ7mdHXy1btqxt7cUXXyydd+bMmaX10dHR0vru3btL61cq7mcHkiPsQBKEHUiCsANJEHYgCcIOJEHYgSS4nx19tWrVqra1TufRd+3aVVp/5ZVXeuopq45bdttP2j5je3LatEdtn7C9t/hr/18UwFDoZjf+95JWtpj+m4hYVPw9X29bAOrWMewRsVvS2QH0AqCPqhyge8D2m8Vu/ux2b7I9ZnvC9kSFZQGoqNewb5K0UNIiSScl/ardGyNiPCKWRMSSHpcFoAY9hT0iTkfEpxHxL0m/k7S03rYA1K2nsNsemfbye5Im270XwHDoeJ7d9lOSRiVda/u4pI2SRm0vkhSSjkr6UR97xBC76qqrSusrV7Y6kTPlwoULpfNu3LixtP7JJ5+U1vF5HcMeEWtbTH6iD70A6CMulwWSIOxAEoQdSIKwA0kQdiAJbnFFJRs2bCitL168uG3thRdeKJ335Zdf7qkntMaWHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSYMhmlLr77rtL688880xp/aOPPmpbK7v9VZJeffXV0jpaY8hmIDnCDiRB2IEkCDuQBGEHkiDsQBKEHUiC+9mTu+aaa0rrjz/+eGl9xowZpfXnn28/5ifn0QeLLTuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJMH97Fe4TufBO53rvu2220rr77zzTmm97J71TvOiNz3fz257vu2/2n7L9n7bPy6mz7G90/bbxePsupsGUJ9uduMvSvppRHxL0h2S1tv+lqSHJe2KiJsk7SpeAxhSHcMeEScj4vXi+TlJByTNk7Ra0ubibZsl3dOvJgFU96Wujbe9QNJiSX+XNDciThalU5LmtplnTNJY7y0CqEPXR+Ntz5K0TdJPIuKf02sxdZSv5cG3iBiPiCURsaRSpwAq6SrstmdqKuhbIuLPxeTTtkeK+oikM/1pEUAdOu7G27akJyQdiIhfTyttl7RO0i+Kx2f70iEqWbhwYWm906m1Th566KHSOqfXhkc339mXSfqBpH229xbTHtFUyLfa/qGkdyXd158WAdShY9gj4m+SWp6kl7Si3nYA9AuXywJJEHYgCcIOJEHYgSQIO5AEPyV9Bbjxxhvb1nbs2FHpszds2FBaf+655yp9PgaHLTuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJMF59ivA2Fj7X/264YYbKn32Sy+9VFof5E+Roxq27EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBOfZLwPLly8vrT/44IMD6gSXM7bsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5BEN+Ozz5f0B0lzJYWk8Yj4re1HJd0v6YPirY9ExPP9ajSzO++8s7Q+a9asnj+70/jp58+f7/mzMVy6uajmoqSfRsTrtr8maY/tnUXtNxHxy/61B6Au3YzPflLSyeL5OdsHJM3rd2MA6vWlvrPbXiBpsaS/F5MesP2m7Sdtz24zz5jtCdsTlToFUEnXYbc9S9I2ST+JiH9K2iRpoaRFmtry/6rVfBExHhFLImJJDf0C6FFXYbc9U1NB3xIRf5akiDgdEZ9GxL8k/U7S0v61CaCqjmG3bUlPSDoQEb+eNn1k2tu+J2my/vYA1KWbo/HLJP1A0j7be4tpj0haa3uRpk7HHZX0o750iEreeOON0vqKFStK62fPnq2zHTSom6Pxf5PkFiXOqQOXEa6gA5Ig7EAShB1IgrADSRB2IAnCDiThQQ65a5vxfYE+i4hWp8rZsgNZEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoMesvkfkt6d9vraYtowGtbehrUvid56VWdvN7YrDPSimi8s3J4Y1t+mG9behrUvid56Naje2I0HkiDsQBJNh3284eWXGdbehrUvid56NZDeGv3ODmBwmt6yAxgQwg4k0UjYba+0fdD2YdsPN9FDO7aP2t5ne2/T49MVY+idsT05bdoc2zttv108thxjr6HeHrV9olh3e22vaqi3+bb/avst2/tt/7iY3ui6K+lrIOtt4N/Zbc+QdEjSdyQdl/SapLUR8dZAG2nD9lFJSyKi8QswbH9b0nlJf4iI/y6mPSbpbET8ovgf5eyI+NmQ9PaopPNND+NdjFY0Mn2YcUn3SPpfNbjuSvq6TwNYb01s2ZdKOhwRRyLigqQ/SVrdQB9DLyJ2S7p0SJbVkjYXzzdr6h/LwLXpbShExMmIeL14fk7SZ8OMN7ruSvoaiCbCPk/SsWmvj2u4xnsPSTts77E91nQzLcyNiJPF81OS5jbZTAsdh/EepEuGGR+addfL8OdVcYDui5ZHxK2S/kfS+mJ3dSjF1HewYTp32tUw3oPSYpjx/2hy3fU6/HlVTYT9hKT5015/vZg2FCLiRPF4RtLTGr6hqE9/NoJu8Xim4X7+Y5iG8W41zLiGYN01Ofx5E2F/TdJNtr9h+6uSvi9pewN9fIHtq4sDJ7J9taTvaviGot4uaV3xfJ2kZxvs5XOGZRjvdsOMq+F11/jw5xEx8D9JqzR1RP4dST9vooc2fX1T0hvF3/6me5P0lKZ26z7R1LGNH0q6RtIuSW9L+n9Jc4aotz9K2ifpTU0Fa6Sh3pZrahf9TUl7i79VTa+7kr4Gst64XBZIggN0QBKEHUiCsANJEHYgCcIOJEHYgSQIO5DEvwEvYRv57rmVLgAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "adv\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0YieNotbQWgo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}